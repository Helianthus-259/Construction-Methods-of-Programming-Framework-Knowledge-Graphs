[
  {
    "entityId": "org.springframework.core.io.AbstractResource#debug(Supplier<String>,Throwable)",
    "entityType": "method",
    "code": "/**\r\n * Lazily access the logger for debug logging in case of an exception.\r\n */\r\nprivate void debug(Supplier<String> message, Throwable ex) {\r\n    Log logger = LogFactory.getLog(getClass());\r\n    if (logger.isDebugEnabled()) {\r\n        logger.debug(message.get(), ex);\r\n    }\r\n}",
    "comment": "\n\t * Lazily access the logger for debug logging in case of an exception.\n\t "
  },
  {
    "entityId": "org.springframework.core.io.AbstractResource#equals(Object)",
    "entityType": "method",
    "code": "/**\r\n * This implementation compares description strings.\r\n * @see #getDescription()\r\n */\r\n@Override\r\npublic boolean equals(@Nullable Object other) {\r\n    return (this == other || (other instanceof Resource that && getDescription().equals(that.getDescription())));\r\n}",
    "comment": "\n\t * This implementation compares description strings.\n\t * @see #getDescription()\n\t "
  },
  {
    "entityId": "org.springframework.core.io.AbstractResource#hashCode()",
    "entityType": "method",
    "code": "/**\r\n * This implementation returns the description's hash code.\r\n * @see #getDescription()\r\n */\r\n@Override\r\npublic int hashCode() {\r\n    return getDescription().hashCode();\r\n}",
    "comment": "\n\t * This implementation returns the description's hash code.\n\t * @see #getDescription()\n\t "
  },
  {
    "entityId": "org.springframework.core.io.AbstractResource#toString()",
    "entityType": "method",
    "code": "/**\r\n * This implementation returns the description of this resource.\r\n * @see #getDescription()\r\n */\r\n@Override\r\npublic String toString() {\r\n    return getDescription();\r\n}",
    "comment": "\n\t * This implementation returns the description of this resource.\n\t * @see #getDescription()\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.CloseableDataBuffer",
    "entityType": "class",
    "code": "/**\r\n * Closes this data buffer, freeing any resources.\r\n * @throws IllegalStateException if this buffer has already been closed\r\n */\r\n@Override\r\nvoid close();",
    "comment": "\n * Extension of {@link DataBuffer} that allows for buffers that can be used\n * in a {@code try}-with-resources statement.\n\n * @author Arjen Poutsma\n * @since 6.0\n "
  },
  {
    "entityId": "org.springframework.core.io.buffer.CloseableDataBuffer#close()",
    "entityType": "method",
    "code": "/**\r\n * Closes this data buffer, freeing any resources.\r\n * @throws IllegalStateException if this buffer has already been closed\r\n */\r\n@Override\r\nvoid close();",
    "comment": "\n\t * Closes this data buffer, freeing any resources.\n\t * @throws IllegalStateException if this buffer has already been closed\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer",
    "entityType": "class",
    "code": "/**\r\n * Return the {@link DataBufferFactory} that created this buffer.\r\n * @return the creating buffer factory\r\n */\r\nDataBufferFactory factory();\n/**\r\n * Return the index of the first byte in this buffer that matches\r\n * the given predicate.\r\n * @param predicate the predicate to match\r\n * @param fromIndex the index to start the search from\r\n * @return the index of the first byte that matches {@code predicate};\r\n * or {@code -1} if none match\r\n */\r\nint indexOf(IntPredicate predicate, int fromIndex);\n/**\r\n * Return the index of the last byte in this buffer that matches\r\n * the given predicate.\r\n * @param predicate the predicate to match\r\n * @param fromIndex the index to start the search from\r\n * @return the index of the last byte that matches {@code predicate};\r\n * or {@code -1} if none match\r\n */\r\nint lastIndexOf(IntPredicate predicate, int fromIndex);\n/**\r\n * Return the number of bytes that can be read from this data buffer.\r\n * @return the readable byte count\r\n */\r\nint readableByteCount();\n/**\r\n * Return the number of bytes that can be written to this data buffer.\r\n * @return the writable byte count\r\n * @since 5.0.1\r\n */\r\nint writableByteCount();\n/**\r\n * Return the number of bytes that this buffer can contain.\r\n * @return the capacity\r\n * @since 5.0.1\r\n */\r\nint capacity();\n/**\r\n * Set the number of bytes that this buffer can contain.\r\n * <p>If the new capacity is lower than the current capacity, the contents\r\n * of this buffer will be truncated. If the new capacity is higher than\r\n * the current capacity, it will be expanded.\r\n * @param capacity the new capacity\r\n * @return this buffer\r\n * @deprecated as of 6.0, in favor of {@link #ensureWritable(int)}, which\r\n * has different semantics\r\n */\r\n@Deprecated(since = \"6.0\")\r\nDataBuffer capacity(int capacity);\n/**\r\n * Ensure that the current buffer has enough {@link #writableByteCount()}\r\n * to write the amount of data given as an argument. If not, the missing\r\n * capacity will be added to the buffer.\r\n * @param capacity the writable capacity to check for\r\n * @return this buffer\r\n * @since 5.1.4\r\n * @deprecated since 6.0, in favor of {@link #ensureWritable(int)}\r\n */\r\n@Deprecated(since = \"6.0\")\r\ndefault DataBuffer ensureCapacity(int capacity) {\r\n    return ensureWritable(capacity);\r\n}\n/**\r\n * Ensure that the current buffer has enough {@link #writableByteCount()}\r\n * to write the amount of data given as an argument. If not, the missing\r\n * capacity will be added to the buffer.\r\n * @param capacity the writable capacity to check for\r\n * @return this buffer\r\n * @since 6.0\r\n */\r\nDataBuffer ensureWritable(int capacity);\n/**\r\n * Return the position from which this buffer will read.\r\n * @return the read position\r\n * @since 5.0.1\r\n */\r\nint readPosition();\n/**\r\n * Set the position from which this buffer will read.\r\n * @param readPosition the new read position\r\n * @return this buffer\r\n * @throws IndexOutOfBoundsException if {@code readPosition} is smaller than 0\r\n * or greater than {@link #writePosition()}\r\n * @since 5.0.1\r\n */\r\nDataBuffer readPosition(int readPosition);\n/**\r\n * Return the position to which this buffer will write.\r\n * @return the write position\r\n * @since 5.0.1\r\n */\r\nint writePosition();\n/**\r\n * Set the position to which this buffer will write.\r\n * @param writePosition the new write position\r\n * @return this buffer\r\n * @throws IndexOutOfBoundsException if {@code writePosition} is smaller than\r\n * {@link #readPosition()} or greater than {@link #capacity()}\r\n * @since 5.0.1\r\n */\r\nDataBuffer writePosition(int writePosition);\n/**\r\n * Read a single byte at the given index from this data buffer.\r\n * @param index the index at which the byte will be read\r\n * @return the byte at the given index\r\n * @throws IndexOutOfBoundsException when {@code index} is out of bounds\r\n * @since 5.0.4\r\n */\r\nbyte getByte(int index);\n/**\r\n * Read a single byte from the current reading position from this data buffer.\r\n * @return the byte at this buffer's current reading position\r\n */\r\nbyte read();\n/**\r\n * Read this buffer's data into the specified destination, starting at the current\r\n * reading position of this buffer.\r\n * @param destination the array into which the bytes are to be written\r\n * @return this buffer\r\n */\r\nDataBuffer read(byte[] destination);\n/**\r\n * Read at most {@code length} bytes of this buffer into the specified destination,\r\n * starting at the current reading position of this buffer.\r\n * @param destination the array into which the bytes are to be written\r\n * @param offset the index within {@code destination} of the first byte to be written\r\n * @param length the maximum number of bytes to be written in {@code destination}\r\n * @return this buffer\r\n */\r\nDataBuffer read(byte[] destination, int offset, int length);\n/**\r\n * Write a single byte into this buffer at the current writing position.\r\n * @param b the byte to be written\r\n * @return this buffer\r\n */\r\nDataBuffer write(byte b);\n/**\r\n * Write the given source into this buffer, starting at the current writing position\r\n * of this buffer.\r\n * @param source the bytes to be written into this buffer\r\n * @return this buffer\r\n */\r\nDataBuffer write(byte[] source);\n/**\r\n * Write at most {@code length} bytes of the given source into this buffer, starting\r\n * at the current writing position of this buffer.\r\n * @param source the bytes to be written into this buffer\r\n * @param offset the index within {@code source} to start writing from\r\n * @param length the maximum number of bytes to be written from {@code source}\r\n * @return this buffer\r\n */\r\nDataBuffer write(byte[] source, int offset, int length);\n/**\r\n * Write one or more {@code DataBuffer}s to this buffer, starting at the current\r\n * writing position. It is the responsibility of the caller to\r\n * {@linkplain DataBufferUtils#release(DataBuffer) release} the given data buffers.\r\n * @param buffers the byte buffers to write into this buffer\r\n * @return this buffer\r\n */\r\nDataBuffer write(DataBuffer... buffers);\n/**\r\n * Write one or more {@link ByteBuffer} to this buffer, starting at the current\r\n * writing position.\r\n * @param buffers the byte buffers to write into this buffer\r\n * @return this buffer\r\n */\r\nDataBuffer write(ByteBuffer... buffers);\n/**\r\n * Write the given {@code CharSequence} using the given {@code Charset},\r\n * starting at the current writing position.\r\n * @param charSequence the char sequence to write into this buffer\r\n * @param charset the charset to encode the char sequence with\r\n * @return this buffer\r\n * @since 5.1.4\r\n */\r\ndefault DataBuffer write(CharSequence charSequence, Charset charset) {\r\n    Assert.notNull(charSequence, \"CharSequence must not be null\");\r\n    Assert.notNull(charset, \"Charset must not be null\");\r\n    if (!charSequence.isEmpty()) {\r\n        CharsetEncoder encoder = charset.newEncoder().onMalformedInput(CodingErrorAction.REPLACE).onUnmappableCharacter(CodingErrorAction.REPLACE);\r\n        CharBuffer src = CharBuffer.wrap(charSequence);\r\n        int averageSize = (int) Math.ceil(src.remaining() * encoder.averageBytesPerChar());\r\n        ensureWritable(averageSize);\r\n        while (true) {\r\n            CoderResult cr;\r\n            if (src.hasRemaining()) {\r\n                try (ByteBufferIterator iterator = writableByteBuffers()) {\r\n                    Assert.state(iterator.hasNext(), \"No ByteBuffer available\");\r\n                    ByteBuffer dest = iterator.next();\r\n                    cr = encoder.encode(src, dest, true);\r\n                    if (cr.isUnderflow()) {\r\n                        cr = encoder.flush(dest);\r\n                    }\r\n                    writePosition(writePosition() + dest.position());\r\n                }\r\n            } else {\r\n                cr = CoderResult.UNDERFLOW;\r\n            }\r\n            if (cr.isUnderflow()) {\r\n                break;\r\n            } else if (cr.isOverflow()) {\r\n                int maxSize = (int) Math.ceil(src.remaining() * encoder.maxBytesPerChar());\r\n                ensureWritable(maxSize);\r\n            }\r\n        }\r\n    }\r\n    return this;\r\n}\n/**\r\n * Create a new {@code DataBuffer} whose contents is a shared subsequence of this\r\n * data buffer's content.  Data between this data buffer and the returned buffer is\r\n * shared; though changes in the returned buffer's position will not be reflected\r\n * in the reading nor writing position of this data buffer.\r\n * <p><strong>Note</strong> that this method will <strong>not</strong> call\r\n * {@link DataBufferUtils#retain(DataBuffer)} on the resulting slice: the reference\r\n * count will not be increased.\r\n * @param index the index at which to start the slice\r\n * @param length the length of the slice\r\n * @return the specified slice of this data buffer\r\n * @deprecated as of 6.0, in favor of {@link #split(int)}, which\r\n * has different semantics\r\n */\r\n@Deprecated(since = \"6.0\")\r\nDataBuffer slice(int index, int length);\n/**\r\n * Create a new {@code DataBuffer} whose contents is a shared, retained subsequence of this\r\n * data buffer's content.  Data between this data buffer and the returned buffer is\r\n * shared; though changes in the returned buffer's position will not be reflected\r\n * in the reading nor writing position of this data buffer.\r\n * <p><strong>Note</strong> that unlike {@link #slice(int, int)}, this method\r\n * <strong>will</strong> call {@link DataBufferUtils#retain(DataBuffer)} (or equivalent) on the\r\n * resulting slice.\r\n * @param index the index at which to start the slice\r\n * @param length the length of the slice\r\n * @return the specified, retained slice of this data buffer\r\n * @since 5.2\r\n * @deprecated as of 6.0, in favor of {@link #split(int)}, which\r\n * has different semantics\r\n */\r\n@Deprecated(since = \"6.0\")\r\ndefault DataBuffer retainedSlice(int index, int length) {\r\n    return DataBufferUtils.retain(slice(index, length));\r\n}\n/**\r\n * Splits this data buffer into two at the given index.\r\n *\r\n * <p>Data that precedes the {@code index} will be returned in a new buffer,\r\n * while this buffer will contain data that follows after {@code index}.\r\n * Memory between the two buffers is shared, but independent and cannot\r\n * overlap (unlike {@link #slice(int, int) slice}).\r\n *\r\n * <p>The {@linkplain #readPosition() read} and\r\n * {@linkplain #writePosition() write} position of the returned buffer are\r\n * truncated to fit within the buffers {@linkplain #capacity() capacity} if\r\n * necessary. The positions of this buffer are set to {@code 0} if they are\r\n * smaller than {@code index}.\r\n * @param index the index at which it should be split\r\n * @return a new data buffer, containing the bytes from index {@code 0} to\r\n * {@code index}\r\n * @since 6.0\r\n */\r\nDataBuffer split(int index);\n/**\r\n * Expose this buffer's bytes as a {@link ByteBuffer}. Data between this\r\n * {@code DataBuffer} and the returned {@code ByteBuffer} is shared; though\r\n * changes in the returned buffer's {@linkplain ByteBuffer#position() position}\r\n * will not be reflected in the reading nor writing position of this data buffer.\r\n * @return this data buffer as a byte buffer\r\n * @deprecated as of 6.0, in favor of {@link #toByteBuffer(ByteBuffer)},\r\n * {@link #readableByteBuffers()}, or {@link #writableByteBuffers()}.\r\n */\r\n@Deprecated(since = \"6.0\")\r\nByteBuffer asByteBuffer();\n/**\r\n * Expose a subsequence of this buffer's bytes as a {@link ByteBuffer}. Data between\r\n * this {@code DataBuffer} and the returned {@code ByteBuffer} is shared; though\r\n * changes in the returned buffer's {@linkplain ByteBuffer#position() position}\r\n * will not be reflected in the reading nor writing position of this data buffer.\r\n * @param index the index at which to start the byte buffer\r\n * @param length the length of the returned byte buffer\r\n * @return this data buffer as a byte buffer\r\n * @since 5.0.1\r\n * @deprecated as of 6.0, in favor of {@link #toByteBuffer(int, ByteBuffer, int, int)},\r\n * {@link #readableByteBuffers()}, or {@link #writableByteBuffers()}.\r\n */\r\n@Deprecated(since = \"6.0\")\r\nByteBuffer asByteBuffer(int index, int length);\n/**\r\n * Returns a {@link ByteBuffer} representation of this data buffer. Data\r\n * between this {@code DataBuffer} and the returned {@code ByteBuffer} is\r\n * <strong>not</strong> shared.\r\n * @return this data buffer as a byte buffer\r\n * @since 6.0\r\n * @see #readableByteBuffers()\r\n * @see #writableByteBuffers()\r\n * @deprecated as of 6.0.5, in favor of {@link #toByteBuffer(ByteBuffer)}\r\n */\r\n@Deprecated(since = \"6.0.5\")\r\ndefault ByteBuffer toByteBuffer() {\r\n    return toByteBuffer(readPosition(), readableByteCount());\r\n}\n/**\r\n * Returns a {@link ByteBuffer} representation of a subsequence of this\r\n * buffer's bytes. Data between this {@code DataBuffer} and the returned\r\n * {@code ByteBuffer} is <strong>not</strong> shared.\r\n * @return this data buffer as a byte buffer\r\n * @since 6.0\r\n * @see #readableByteBuffers()\r\n * @see #writableByteBuffers()\r\n * @deprecated as of 6.0.5, in favor of\r\n * {@link #toByteBuffer(int, ByteBuffer, int, int)}\r\n */\r\n@Deprecated(since = \"6.0.5\")\r\nByteBuffer toByteBuffer(int index, int length);\n/**\r\n * Copies this entire data buffer into the given destination\r\n * {@code ByteBuffer}, beginning at the current\r\n * {@linkplain #readPosition() reading position}, and the current\r\n * {@linkplain ByteBuffer#position() position} of destination byte buffer.\r\n * @param dest the destination byte buffer\r\n * @since 6.0.5\r\n */\r\ndefault void toByteBuffer(ByteBuffer dest) {\r\n    toByteBuffer(readPosition(), dest, dest.position(), readableByteCount());\r\n}\n/**\r\n * Copies the given length from this data buffer into the given destination\r\n * {@code ByteBuffer}, beginning at the given source position, and the\r\n * given destination position in the destination byte buffer.\r\n * @param srcPos the position of this data buffer from where copying should start\r\n * @param dest the destination byte buffer\r\n * @param destPos the position in {@code dest} to where copying should start\r\n * @param length the amount of data to copy\r\n * @since 6.0.5\r\n */\r\nvoid toByteBuffer(int srcPos, ByteBuffer dest, int destPos, int length);\n/**\r\n * Returns a closeable iterator over each {@link ByteBuffer} in this data\r\n * buffer that can be read. Calling this method is more efficient than\r\n * {@link #toByteBuffer()}, as no data is copied. However, the byte buffers\r\n * provided can only be used during the iteration.\r\n * <p><b>Note</b> that the returned iterator must be used in a\r\n * try-with-resources clause or explicitly\r\n * {@linkplain ByteBufferIterator#close() closed}.\r\n * @return a closeable iterator over the readable byte buffers contained in this data buffer\r\n * @since 6.0.5\r\n */\r\nByteBufferIterator readableByteBuffers();\n/**\r\n * Returns a closeable iterator over each {@link ByteBuffer} in this data\r\n * buffer that can be written to. The byte buffers provided can only be used\r\n * during the iteration.\r\n * <p><b>Note</b> that the returned iterator must be used in a\r\n * try-with-resources clause or explicitly\r\n * {@linkplain ByteBufferIterator#close() closed}.\r\n * @return a closeable iterator over the writable byte buffers contained in this data buffer\r\n * @since 6.0.5\r\n */\r\nByteBufferIterator writableByteBuffers();\n/**\r\n * Expose this buffer's data as an {@link InputStream}. Both data and read position are\r\n * shared between the returned stream and this data buffer. The underlying buffer will\r\n * <strong>not</strong> be {@linkplain DataBufferUtils#release(DataBuffer) released}\r\n * when the input stream is {@linkplain InputStream#close() closed}.\r\n * @return this data buffer as an input stream\r\n * @see #asInputStream(boolean)\r\n */\r\ndefault InputStream asInputStream() {\r\n    return new DataBufferInputStream(this, false);\r\n}\n/**\r\n * Expose this buffer's data as an {@link InputStream}. Both data and read position are\r\n * shared between the returned stream and this data buffer.\r\n * @param releaseOnClose whether the underlying buffer will be\r\n * {@linkplain DataBufferUtils#release(DataBuffer) released} when the input stream is\r\n * {@linkplain InputStream#close() closed}.\r\n * @return this data buffer as an input stream\r\n * @since 5.0.4\r\n */\r\ndefault InputStream asInputStream(boolean releaseOnClose) {\r\n    return new DataBufferInputStream(this, releaseOnClose);\r\n}\n/**\r\n * Expose this buffer's data as an {@link OutputStream}. Both data and write position are\r\n * shared between the returned stream and this data buffer.\r\n * @return this data buffer as an output stream\r\n */\r\ndefault OutputStream asOutputStream() {\r\n    return new DataBufferOutputStream(this);\r\n}\n/**\r\n * Return this buffer's data a String using the specified charset. Default implementation\r\n * delegates to {@code toString(readPosition(), readableByteCount(), charset)}.\r\n * @param charset the character set to use\r\n * @return a string representation of all this buffers data\r\n * @since 5.2\r\n */\r\ndefault String toString(Charset charset) {\r\n    Assert.notNull(charset, \"Charset must not be null\");\r\n    return toString(readPosition(), readableByteCount(), charset);\r\n}\n/**\r\n * Return a part of this buffer's data as a String using the specified charset.\r\n * @param index the index at which to start the string\r\n * @param length the number of bytes to use for the string\r\n * @param charset the charset to use\r\n * @return a string representation of a part of this buffers data\r\n * @since 5.2\r\n */\r\nString toString(int index, int length, Charset charset);\n/**\r\n * A dedicated iterator type that ensures the lifecycle of iterated\r\n * {@link ByteBuffer} elements. This iterator must be used in a\r\n * try-with-resources clause or explicitly {@linkplain #close() closed}.\r\n * @since 6.0.5\r\n * @see DataBuffer#readableByteBuffers()\r\n * @see DataBuffer#writableByteBuffers()\r\n */\r\ninterface ByteBufferIterator extends Iterator<ByteBuffer>, Closeable {\r\n\r\n    @Override\r\n    void close();\r\n}",
    "comment": "\n * Basic abstraction over byte buffers.\n *\n * <p>{@code DataBuffer}s has a separate {@linkplain #readPosition() read} and\n * {@linkplain #writePosition() write} position, as opposed to {@code ByteBuffer}'s\n * single {@linkplain ByteBuffer#position() position}. As such, the {@code DataBuffer}\n * does not require a {@linkplain ByteBuffer#flip() flip} to read after writing. In general,\n * the following invariant holds for the read and write positions, and the capacity:\n *\n * <blockquote>\n *     {@code 0} {@code <=}\n *     <i>readPosition</i> {@code <=}\n *     <i>writePosition</i> {@code <=}\n *     <i>capacity</i>\n * </blockquote>\n *\n * <p>The {@linkplain #capacity() capacity} of a {@code DataBuffer} is expanded on demand,\n * similar to {@code StringBuilder}.\n *\n * <p>The main purpose of the {@code DataBuffer} abstraction is to provide a convenient wrapper\n * around {@link ByteBuffer} which is similar to Netty's {@link io.netty.buffer.ByteBuf} but\n * can also be used on non-Netty platforms (i.e. Servlet containers).\n *\n * @author Arjen Poutsma\n * @author Brian Clozel\n * @since 5.0\n * @see DataBufferFactory\n "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#factory()",
    "entityType": "method",
    "code": "/**\r\n * Return the {@link DataBufferFactory} that created this buffer.\r\n * @return the creating buffer factory\r\n */\r\nDataBufferFactory factory();",
    "comment": "\n\t * Return the {@link DataBufferFactory} that created this buffer.\n\t * @return the creating buffer factory\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#indexOf(IntPredicate,int)",
    "entityType": "method",
    "code": "/**\r\n * Return the index of the first byte in this buffer that matches\r\n * the given predicate.\r\n * @param predicate the predicate to match\r\n * @param fromIndex the index to start the search from\r\n * @return the index of the first byte that matches {@code predicate};\r\n * or {@code -1} if none match\r\n */\r\nint indexOf(IntPredicate predicate, int fromIndex);",
    "comment": "\n\t * Return the index of the first byte in this buffer that matches\n\t * the given predicate.\n\t * @param predicate the predicate to match\n\t * @param fromIndex the index to start the search from\n\t * @return the index of the first byte that matches {@code predicate};\n\t * or {@code -1} if none match\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#lastIndexOf(IntPredicate,int)",
    "entityType": "method",
    "code": "/**\r\n * Return the index of the last byte in this buffer that matches\r\n * the given predicate.\r\n * @param predicate the predicate to match\r\n * @param fromIndex the index to start the search from\r\n * @return the index of the last byte that matches {@code predicate};\r\n * or {@code -1} if none match\r\n */\r\nint lastIndexOf(IntPredicate predicate, int fromIndex);",
    "comment": "\n\t * Return the index of the last byte in this buffer that matches\n\t * the given predicate.\n\t * @param predicate the predicate to match\n\t * @param fromIndex the index to start the search from\n\t * @return the index of the last byte that matches {@code predicate};\n\t * or {@code -1} if none match\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#readableByteCount()",
    "entityType": "method",
    "code": "/**\r\n * Return the number of bytes that can be read from this data buffer.\r\n * @return the readable byte count\r\n */\r\nint readableByteCount();",
    "comment": "\n\t * Return the number of bytes that can be read from this data buffer.\n\t * @return the readable byte count\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#writableByteCount()",
    "entityType": "method",
    "code": "/**\r\n * Return the number of bytes that can be written to this data buffer.\r\n * @return the writable byte count\r\n * @since 5.0.1\r\n */\r\nint writableByteCount();",
    "comment": "\n\t * Return the number of bytes that can be written to this data buffer.\n\t * @return the writable byte count\n\t * @since 5.0.1\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#capacity()",
    "entityType": "method",
    "code": "/**\r\n * Return the number of bytes that this buffer can contain.\r\n * @return the capacity\r\n * @since 5.0.1\r\n */\r\nint capacity();",
    "comment": "\n\t * Return the number of bytes that this buffer can contain.\n\t * @return the capacity\n\t * @since 5.0.1\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#capacity(int)",
    "entityType": "method",
    "code": "/**\r\n * Set the number of bytes that this buffer can contain.\r\n * <p>If the new capacity is lower than the current capacity, the contents\r\n * of this buffer will be truncated. If the new capacity is higher than\r\n * the current capacity, it will be expanded.\r\n * @param capacity the new capacity\r\n * @return this buffer\r\n * @deprecated as of 6.0, in favor of {@link #ensureWritable(int)}, which\r\n * has different semantics\r\n */\r\n@Deprecated(since = \"6.0\")\r\nDataBuffer capacity(int capacity);",
    "comment": "\n\t * Set the number of bytes that this buffer can contain.\n\t * <p>If the new capacity is lower than the current capacity, the contents\n\t * of this buffer will be truncated. If the new capacity is higher than\n\t * the current capacity, it will be expanded.\n\t * @param capacity the new capacity\n\t * @return this buffer\n\t * @deprecated as of 6.0, in favor of {@link #ensureWritable(int)}, which\n\t * has different semantics\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#ensureCapacity(int)",
    "entityType": "method",
    "code": "/**\r\n * Ensure that the current buffer has enough {@link #writableByteCount()}\r\n * to write the amount of data given as an argument. If not, the missing\r\n * capacity will be added to the buffer.\r\n * @param capacity the writable capacity to check for\r\n * @return this buffer\r\n * @since 5.1.4\r\n * @deprecated since 6.0, in favor of {@link #ensureWritable(int)}\r\n */\r\n@Deprecated(since = \"6.0\")\r\ndefault DataBuffer ensureCapacity(int capacity) {\r\n    return ensureWritable(capacity);\r\n}",
    "comment": "\n\t * Ensure that the current buffer has enough {@link #writableByteCount()}\n\t * to write the amount of data given as an argument. If not, the missing\n\t * capacity will be added to the buffer.\n\t * @param capacity the writable capacity to check for\n\t * @return this buffer\n\t * @since 5.1.4\n\t * @deprecated since 6.0, in favor of {@link #ensureWritable(int)}\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#ensureWritable(int)",
    "entityType": "method",
    "code": "/**\r\n * Ensure that the current buffer has enough {@link #writableByteCount()}\r\n * to write the amount of data given as an argument. If not, the missing\r\n * capacity will be added to the buffer.\r\n * @param capacity the writable capacity to check for\r\n * @return this buffer\r\n * @since 6.0\r\n */\r\nDataBuffer ensureWritable(int capacity);",
    "comment": "\n\t * Ensure that the current buffer has enough {@link #writableByteCount()}\n\t * to write the amount of data given as an argument. If not, the missing\n\t * capacity will be added to the buffer.\n\t * @param capacity the writable capacity to check for\n\t * @return this buffer\n\t * @since 6.0\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#readPosition()",
    "entityType": "method",
    "code": "/**\r\n * Return the position from which this buffer will read.\r\n * @return the read position\r\n * @since 5.0.1\r\n */\r\nint readPosition();",
    "comment": "\n\t * Return the position from which this buffer will read.\n\t * @return the read position\n\t * @since 5.0.1\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#readPosition(int)",
    "entityType": "method",
    "code": "/**\r\n * Set the position from which this buffer will read.\r\n * @param readPosition the new read position\r\n * @return this buffer\r\n * @throws IndexOutOfBoundsException if {@code readPosition} is smaller than 0\r\n * or greater than {@link #writePosition()}\r\n * @since 5.0.1\r\n */\r\nDataBuffer readPosition(int readPosition);",
    "comment": "\n\t * Set the position from which this buffer will read.\n\t * @param readPosition the new read position\n\t * @return this buffer\n\t * @throws IndexOutOfBoundsException if {@code readPosition} is smaller than 0\n\t * or greater than {@link #writePosition()}\n\t * @since 5.0.1\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#writePosition()",
    "entityType": "method",
    "code": "/**\r\n * Return the position to which this buffer will write.\r\n * @return the write position\r\n * @since 5.0.1\r\n */\r\nint writePosition();",
    "comment": "\n\t * Return the position to which this buffer will write.\n\t * @return the write position\n\t * @since 5.0.1\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#writePosition(int)",
    "entityType": "method",
    "code": "/**\r\n * Set the position to which this buffer will write.\r\n * @param writePosition the new write position\r\n * @return this buffer\r\n * @throws IndexOutOfBoundsException if {@code writePosition} is smaller than\r\n * {@link #readPosition()} or greater than {@link #capacity()}\r\n * @since 5.0.1\r\n */\r\nDataBuffer writePosition(int writePosition);",
    "comment": "\n\t * Set the position to which this buffer will write.\n\t * @param writePosition the new write position\n\t * @return this buffer\n\t * @throws IndexOutOfBoundsException if {@code writePosition} is smaller than\n\t * {@link #readPosition()} or greater than {@link #capacity()}\n\t * @since 5.0.1\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#getByte(int)",
    "entityType": "method",
    "code": "/**\r\n * Read a single byte at the given index from this data buffer.\r\n * @param index the index at which the byte will be read\r\n * @return the byte at the given index\r\n * @throws IndexOutOfBoundsException when {@code index} is out of bounds\r\n * @since 5.0.4\r\n */\r\nbyte getByte(int index);",
    "comment": "\n\t * Read a single byte at the given index from this data buffer.\n\t * @param index the index at which the byte will be read\n\t * @return the byte at the given index\n\t * @throws IndexOutOfBoundsException when {@code index} is out of bounds\n\t * @since 5.0.4\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#read()",
    "entityType": "method",
    "code": "/**\r\n * Read a single byte from the current reading position from this data buffer.\r\n * @return the byte at this buffer's current reading position\r\n */\r\nbyte read();",
    "comment": "\n\t * Read a single byte from the current reading position from this data buffer.\n\t * @return the byte at this buffer's current reading position\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#read(byte[])",
    "entityType": "method",
    "code": "/**\r\n * Read this buffer's data into the specified destination, starting at the current\r\n * reading position of this buffer.\r\n * @param destination the array into which the bytes are to be written\r\n * @return this buffer\r\n */\r\nDataBuffer read(byte[] destination);",
    "comment": "\n\t * Read this buffer's data into the specified destination, starting at the current\n\t * reading position of this buffer.\n\t * @param destination the array into which the bytes are to be written\n\t * @return this buffer\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#read(byte[],int,int)",
    "entityType": "method",
    "code": "/**\r\n * Read at most {@code length} bytes of this buffer into the specified destination,\r\n * starting at the current reading position of this buffer.\r\n * @param destination the array into which the bytes are to be written\r\n * @param offset the index within {@code destination} of the first byte to be written\r\n * @param length the maximum number of bytes to be written in {@code destination}\r\n * @return this buffer\r\n */\r\nDataBuffer read(byte[] destination, int offset, int length);",
    "comment": "\n\t * Read at most {@code length} bytes of this buffer into the specified destination,\n\t * starting at the current reading position of this buffer.\n\t * @param destination the array into which the bytes are to be written\n\t * @param offset the index within {@code destination} of the first byte to be written\n\t * @param length the maximum number of bytes to be written in {@code destination}\n\t * @return this buffer\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#write(byte)",
    "entityType": "method",
    "code": "/**\r\n * Write a single byte into this buffer at the current writing position.\r\n * @param b the byte to be written\r\n * @return this buffer\r\n */\r\nDataBuffer write(byte b);",
    "comment": "\n\t * Write a single byte into this buffer at the current writing position.\n\t * @param b the byte to be written\n\t * @return this buffer\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#write(byte[])",
    "entityType": "method",
    "code": "/**\r\n * Write the given source into this buffer, starting at the current writing position\r\n * of this buffer.\r\n * @param source the bytes to be written into this buffer\r\n * @return this buffer\r\n */\r\nDataBuffer write(byte[] source);",
    "comment": "\n\t * Write the given source into this buffer, starting at the current writing position\n\t * of this buffer.\n\t * @param source the bytes to be written into this buffer\n\t * @return this buffer\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#write(byte[],int,int)",
    "entityType": "method",
    "code": "/**\r\n * Write at most {@code length} bytes of the given source into this buffer, starting\r\n * at the current writing position of this buffer.\r\n * @param source the bytes to be written into this buffer\r\n * @param offset the index within {@code source} to start writing from\r\n * @param length the maximum number of bytes to be written from {@code source}\r\n * @return this buffer\r\n */\r\nDataBuffer write(byte[] source, int offset, int length);",
    "comment": "\n\t * Write at most {@code length} bytes of the given source into this buffer, starting\n\t * at the current writing position of this buffer.\n\t * @param source the bytes to be written into this buffer\n\t * @param offset the index within {@code source} to start writing from\n\t * @param length the maximum number of bytes to be written from {@code source}\n\t * @return this buffer\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#write(DataBuffer)",
    "entityType": "method",
    "code": "/**\r\n * Write one or more {@code DataBuffer}s to this buffer, starting at the current\r\n * writing position. It is the responsibility of the caller to\r\n * {@linkplain DataBufferUtils#release(DataBuffer) release} the given data buffers.\r\n * @param buffers the byte buffers to write into this buffer\r\n * @return this buffer\r\n */\r\nDataBuffer write(DataBuffer... buffers);",
    "comment": "\n\t * Write one or more {@code DataBuffer}s to this buffer, starting at the current\n\t * writing position. It is the responsibility of the caller to\n\t * {@linkplain DataBufferUtils#release(DataBuffer) release} the given data buffers.\n\t * @param buffers the byte buffers to write into this buffer\n\t * @return this buffer\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#write(ByteBuffer)",
    "entityType": "method",
    "code": "/**\r\n * Write one or more {@link ByteBuffer} to this buffer, starting at the current\r\n * writing position.\r\n * @param buffers the byte buffers to write into this buffer\r\n * @return this buffer\r\n */\r\nDataBuffer write(ByteBuffer... buffers);",
    "comment": "\n\t * Write one or more {@link ByteBuffer} to this buffer, starting at the current\n\t * writing position.\n\t * @param buffers the byte buffers to write into this buffer\n\t * @return this buffer\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#write(CharSequence,Charset)",
    "entityType": "method",
    "code": "/**\r\n * Write the given {@code CharSequence} using the given {@code Charset},\r\n * starting at the current writing position.\r\n * @param charSequence the char sequence to write into this buffer\r\n * @param charset the charset to encode the char sequence with\r\n * @return this buffer\r\n * @since 5.1.4\r\n */\r\ndefault DataBuffer write(CharSequence charSequence, Charset charset) {\r\n    Assert.notNull(charSequence, \"CharSequence must not be null\");\r\n    Assert.notNull(charset, \"Charset must not be null\");\r\n    if (!charSequence.isEmpty()) {\r\n        CharsetEncoder encoder = charset.newEncoder().onMalformedInput(CodingErrorAction.REPLACE).onUnmappableCharacter(CodingErrorAction.REPLACE);\r\n        CharBuffer src = CharBuffer.wrap(charSequence);\r\n        int averageSize = (int) Math.ceil(src.remaining() * encoder.averageBytesPerChar());\r\n        ensureWritable(averageSize);\r\n        while (true) {\r\n            CoderResult cr;\r\n            if (src.hasRemaining()) {\r\n                try (ByteBufferIterator iterator = writableByteBuffers()) {\r\n                    Assert.state(iterator.hasNext(), \"No ByteBuffer available\");\r\n                    ByteBuffer dest = iterator.next();\r\n                    cr = encoder.encode(src, dest, true);\r\n                    if (cr.isUnderflow()) {\r\n                        cr = encoder.flush(dest);\r\n                    }\r\n                    writePosition(writePosition() + dest.position());\r\n                }\r\n            } else {\r\n                cr = CoderResult.UNDERFLOW;\r\n            }\r\n            if (cr.isUnderflow()) {\r\n                break;\r\n            } else if (cr.isOverflow()) {\r\n                int maxSize = (int) Math.ceil(src.remaining() * encoder.maxBytesPerChar());\r\n                ensureWritable(maxSize);\r\n            }\r\n        }\r\n    }\r\n    return this;\r\n}",
    "comment": "\n\t * Write the given {@code CharSequence} using the given {@code Charset},\n\t * starting at the current writing position.\n\t * @param charSequence the char sequence to write into this buffer\n\t * @param charset the charset to encode the char sequence with\n\t * @return this buffer\n\t * @since 5.1.4\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#slice(int,int)",
    "entityType": "method",
    "code": "/**\r\n * Create a new {@code DataBuffer} whose contents is a shared subsequence of this\r\n * data buffer's content.  Data between this data buffer and the returned buffer is\r\n * shared; though changes in the returned buffer's position will not be reflected\r\n * in the reading nor writing position of this data buffer.\r\n * <p><strong>Note</strong> that this method will <strong>not</strong> call\r\n * {@link DataBufferUtils#retain(DataBuffer)} on the resulting slice: the reference\r\n * count will not be increased.\r\n * @param index the index at which to start the slice\r\n * @param length the length of the slice\r\n * @return the specified slice of this data buffer\r\n * @deprecated as of 6.0, in favor of {@link #split(int)}, which\r\n * has different semantics\r\n */\r\n@Deprecated(since = \"6.0\")\r\nDataBuffer slice(int index, int length);",
    "comment": "\n\t * Create a new {@code DataBuffer} whose contents is a shared subsequence of this\n\t * data buffer's content.  Data between this data buffer and the returned buffer is\n\t * shared; though changes in the returned buffer's position will not be reflected\n\t * in the reading nor writing position of this data buffer.\n\t * <p><strong>Note</strong> that this method will <strong>not</strong> call\n\t * {@link DataBufferUtils#retain(DataBuffer)} on the resulting slice: the reference\n\t * count will not be increased.\n\t * @param index the index at which to start the slice\n\t * @param length the length of the slice\n\t * @return the specified slice of this data buffer\n\t * @deprecated as of 6.0, in favor of {@link #split(int)}, which\n\t * has different semantics\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#retainedSlice(int,int)",
    "entityType": "method",
    "code": "/**\r\n * Create a new {@code DataBuffer} whose contents is a shared, retained subsequence of this\r\n * data buffer's content.  Data between this data buffer and the returned buffer is\r\n * shared; though changes in the returned buffer's position will not be reflected\r\n * in the reading nor writing position of this data buffer.\r\n * <p><strong>Note</strong> that unlike {@link #slice(int, int)}, this method\r\n * <strong>will</strong> call {@link DataBufferUtils#retain(DataBuffer)} (or equivalent) on the\r\n * resulting slice.\r\n * @param index the index at which to start the slice\r\n * @param length the length of the slice\r\n * @return the specified, retained slice of this data buffer\r\n * @since 5.2\r\n * @deprecated as of 6.0, in favor of {@link #split(int)}, which\r\n * has different semantics\r\n */\r\n@Deprecated(since = \"6.0\")\r\ndefault DataBuffer retainedSlice(int index, int length) {\r\n    return DataBufferUtils.retain(slice(index, length));\r\n}",
    "comment": "\n\t * Create a new {@code DataBuffer} whose contents is a shared, retained subsequence of this\n\t * data buffer's content.  Data between this data buffer and the returned buffer is\n\t * shared; though changes in the returned buffer's position will not be reflected\n\t * in the reading nor writing position of this data buffer.\n\t * <p><strong>Note</strong> that unlike {@link #slice(int, int)}, this method\n\t * <strong>will</strong> call {@link DataBufferUtils#retain(DataBuffer)} (or equivalent) on the\n\t * resulting slice.\n\t * @param index the index at which to start the slice\n\t * @param length the length of the slice\n\t * @return the specified, retained slice of this data buffer\n\t * @since 5.2\n\t * @deprecated as of 6.0, in favor of {@link #split(int)}, which\n\t * has different semantics\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#split(int)",
    "entityType": "method",
    "code": "/**\r\n * Splits this data buffer into two at the given index.\r\n *\r\n * <p>Data that precedes the {@code index} will be returned in a new buffer,\r\n * while this buffer will contain data that follows after {@code index}.\r\n * Memory between the two buffers is shared, but independent and cannot\r\n * overlap (unlike {@link #slice(int, int) slice}).\r\n *\r\n * <p>The {@linkplain #readPosition() read} and\r\n * {@linkplain #writePosition() write} position of the returned buffer are\r\n * truncated to fit within the buffers {@linkplain #capacity() capacity} if\r\n * necessary. The positions of this buffer are set to {@code 0} if they are\r\n * smaller than {@code index}.\r\n * @param index the index at which it should be split\r\n * @return a new data buffer, containing the bytes from index {@code 0} to\r\n * {@code index}\r\n * @since 6.0\r\n */\r\nDataBuffer split(int index);",
    "comment": "\n\t * Splits this data buffer into two at the given index.\n\t *\n\t * <p>Data that precedes the {@code index} will be returned in a new buffer,\n\t * while this buffer will contain data that follows after {@code index}.\n\t * Memory between the two buffers is shared, but independent and cannot\n\t * overlap (unlike {@link #slice(int, int) slice}).\n\t *\n\t * <p>The {@linkplain #readPosition() read} and\n\t * {@linkplain #writePosition() write} position of the returned buffer are\n\t * truncated to fit within the buffers {@linkplain #capacity() capacity} if\n\t * necessary. The positions of this buffer are set to {@code 0} if they are\n\t * smaller than {@code index}.\n\t * @param index the index at which it should be split\n\t * @return a new data buffer, containing the bytes from index {@code 0} to\n\t * {@code index}\n\t * @since 6.0\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#asByteBuffer()",
    "entityType": "method",
    "code": "/**\r\n * Expose this buffer's bytes as a {@link ByteBuffer}. Data between this\r\n * {@code DataBuffer} and the returned {@code ByteBuffer} is shared; though\r\n * changes in the returned buffer's {@linkplain ByteBuffer#position() position}\r\n * will not be reflected in the reading nor writing position of this data buffer.\r\n * @return this data buffer as a byte buffer\r\n * @deprecated as of 6.0, in favor of {@link #toByteBuffer(ByteBuffer)},\r\n * {@link #readableByteBuffers()}, or {@link #writableByteBuffers()}.\r\n */\r\n@Deprecated(since = \"6.0\")\r\nByteBuffer asByteBuffer();",
    "comment": "\n\t * Expose this buffer's bytes as a {@link ByteBuffer}. Data between this\n\t * {@code DataBuffer} and the returned {@code ByteBuffer} is shared; though\n\t * changes in the returned buffer's {@linkplain ByteBuffer#position() position}\n\t * will not be reflected in the reading nor writing position of this data buffer.\n\t * @return this data buffer as a byte buffer\n\t * @deprecated as of 6.0, in favor of {@link #toByteBuffer(ByteBuffer)},\n\t * {@link #readableByteBuffers()}, or {@link #writableByteBuffers()}.\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#asByteBuffer(int,int)",
    "entityType": "method",
    "code": "/**\r\n * Expose a subsequence of this buffer's bytes as a {@link ByteBuffer}. Data between\r\n * this {@code DataBuffer} and the returned {@code ByteBuffer} is shared; though\r\n * changes in the returned buffer's {@linkplain ByteBuffer#position() position}\r\n * will not be reflected in the reading nor writing position of this data buffer.\r\n * @param index the index at which to start the byte buffer\r\n * @param length the length of the returned byte buffer\r\n * @return this data buffer as a byte buffer\r\n * @since 5.0.1\r\n * @deprecated as of 6.0, in favor of {@link #toByteBuffer(int, ByteBuffer, int, int)},\r\n * {@link #readableByteBuffers()}, or {@link #writableByteBuffers()}.\r\n */\r\n@Deprecated(since = \"6.0\")\r\nByteBuffer asByteBuffer(int index, int length);",
    "comment": "\n\t * Expose a subsequence of this buffer's bytes as a {@link ByteBuffer}. Data between\n\t * this {@code DataBuffer} and the returned {@code ByteBuffer} is shared; though\n\t * changes in the returned buffer's {@linkplain ByteBuffer#position() position}\n\t * will not be reflected in the reading nor writing position of this data buffer.\n\t * @param index the index at which to start the byte buffer\n\t * @param length the length of the returned byte buffer\n\t * @return this data buffer as a byte buffer\n\t * @since 5.0.1\n\t * @deprecated as of 6.0, in favor of {@link #toByteBuffer(int, ByteBuffer, int, int)},\n\t * {@link #readableByteBuffers()}, or {@link #writableByteBuffers()}.\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#toByteBuffer()",
    "entityType": "method",
    "code": "/**\r\n * Returns a {@link ByteBuffer} representation of this data buffer. Data\r\n * between this {@code DataBuffer} and the returned {@code ByteBuffer} is\r\n * <strong>not</strong> shared.\r\n * @return this data buffer as a byte buffer\r\n * @since 6.0\r\n * @see #readableByteBuffers()\r\n * @see #writableByteBuffers()\r\n * @deprecated as of 6.0.5, in favor of {@link #toByteBuffer(ByteBuffer)}\r\n */\r\n@Deprecated(since = \"6.0.5\")\r\ndefault ByteBuffer toByteBuffer() {\r\n    return toByteBuffer(readPosition(), readableByteCount());\r\n}",
    "comment": "\n\t * Returns a {@link ByteBuffer} representation of this data buffer. Data\n\t * between this {@code DataBuffer} and the returned {@code ByteBuffer} is\n\t * <strong>not</strong> shared.\n\t * @return this data buffer as a byte buffer\n\t * @since 6.0\n\t * @see #readableByteBuffers()\n\t * @see #writableByteBuffers()\n\t * @deprecated as of 6.0.5, in favor of {@link #toByteBuffer(ByteBuffer)}\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#toByteBuffer(int,int)",
    "entityType": "method",
    "code": "/**\r\n * Returns a {@link ByteBuffer} representation of a subsequence of this\r\n * buffer's bytes. Data between this {@code DataBuffer} and the returned\r\n * {@code ByteBuffer} is <strong>not</strong> shared.\r\n * @return this data buffer as a byte buffer\r\n * @since 6.0\r\n * @see #readableByteBuffers()\r\n * @see #writableByteBuffers()\r\n * @deprecated as of 6.0.5, in favor of\r\n * {@link #toByteBuffer(int, ByteBuffer, int, int)}\r\n */\r\n@Deprecated(since = \"6.0.5\")\r\nByteBuffer toByteBuffer(int index, int length);",
    "comment": "\n\t * Returns a {@link ByteBuffer} representation of a subsequence of this\n\t * buffer's bytes. Data between this {@code DataBuffer} and the returned\n\t * {@code ByteBuffer} is <strong>not</strong> shared.\n\t * @return this data buffer as a byte buffer\n\t * @since 6.0\n\t * @see #readableByteBuffers()\n\t * @see #writableByteBuffers()\n\t * @deprecated as of 6.0.5, in favor of\n\t * {@link #toByteBuffer(int, ByteBuffer, int, int)}\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#toByteBuffer(ByteBuffer)",
    "entityType": "method",
    "code": "/**\r\n * Copies this entire data buffer into the given destination\r\n * {@code ByteBuffer}, beginning at the current\r\n * {@linkplain #readPosition() reading position}, and the current\r\n * {@linkplain ByteBuffer#position() position} of destination byte buffer.\r\n * @param dest the destination byte buffer\r\n * @since 6.0.5\r\n */\r\ndefault void toByteBuffer(ByteBuffer dest) {\r\n    toByteBuffer(readPosition(), dest, dest.position(), readableByteCount());\r\n}",
    "comment": "\n\t * Copies this entire data buffer into the given destination\n\t * {@code ByteBuffer}, beginning at the current\n\t * {@linkplain #readPosition() reading position}, and the current\n\t * {@linkplain ByteBuffer#position() position} of destination byte buffer.\n\t * @param dest the destination byte buffer\n\t * @since 6.0.5\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#toByteBuffer(int,ByteBuffer,int,int)",
    "entityType": "method",
    "code": "/**\r\n * Copies the given length from this data buffer into the given destination\r\n * {@code ByteBuffer}, beginning at the given source position, and the\r\n * given destination position in the destination byte buffer.\r\n * @param srcPos the position of this data buffer from where copying should start\r\n * @param dest the destination byte buffer\r\n * @param destPos the position in {@code dest} to where copying should start\r\n * @param length the amount of data to copy\r\n * @since 6.0.5\r\n */\r\nvoid toByteBuffer(int srcPos, ByteBuffer dest, int destPos, int length);",
    "comment": "\n\t * Copies the given length from this data buffer into the given destination\n\t * {@code ByteBuffer}, beginning at the given source position, and the\n\t * given destination position in the destination byte buffer.\n\t * @param srcPos the position of this data buffer from where copying should start\n\t * @param dest the destination byte buffer\n\t * @param destPos the position in {@code dest} to where copying should start\n\t * @param length the amount of data to copy\n\t * @since 6.0.5\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#readableByteBuffers()",
    "entityType": "method",
    "code": "/**\r\n * Returns a closeable iterator over each {@link ByteBuffer} in this data\r\n * buffer that can be read. Calling this method is more efficient than\r\n * {@link #toByteBuffer()}, as no data is copied. However, the byte buffers\r\n * provided can only be used during the iteration.\r\n * <p><b>Note</b> that the returned iterator must be used in a\r\n * try-with-resources clause or explicitly\r\n * {@linkplain ByteBufferIterator#close() closed}.\r\n * @return a closeable iterator over the readable byte buffers contained in this data buffer\r\n * @since 6.0.5\r\n */\r\nByteBufferIterator readableByteBuffers();",
    "comment": "\n\t * Returns a closeable iterator over each {@link ByteBuffer} in this data\n\t * buffer that can be read. Calling this method is more efficient than\n\t * {@link #toByteBuffer()}, as no data is copied. However, the byte buffers\n\t * provided can only be used during the iteration.\n\t * <p><b>Note</b> that the returned iterator must be used in a\n\t * try-with-resources clause or explicitly\n\t * {@linkplain ByteBufferIterator#close() closed}.\n\t * @return a closeable iterator over the readable byte buffers contained in this data buffer\n\t * @since 6.0.5\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#writableByteBuffers()",
    "entityType": "method",
    "code": "/**\r\n * Returns a closeable iterator over each {@link ByteBuffer} in this data\r\n * buffer that can be written to. The byte buffers provided can only be used\r\n * during the iteration.\r\n * <p><b>Note</b> that the returned iterator must be used in a\r\n * try-with-resources clause or explicitly\r\n * {@linkplain ByteBufferIterator#close() closed}.\r\n * @return a closeable iterator over the writable byte buffers contained in this data buffer\r\n * @since 6.0.5\r\n */\r\nByteBufferIterator writableByteBuffers();",
    "comment": "\n\t * Returns a closeable iterator over each {@link ByteBuffer} in this data\n\t * buffer that can be written to. The byte buffers provided can only be used\n\t * during the iteration.\n\t * <p><b>Note</b> that the returned iterator must be used in a\n\t * try-with-resources clause or explicitly\n\t * {@linkplain ByteBufferIterator#close() closed}.\n\t * @return a closeable iterator over the writable byte buffers contained in this data buffer\n\t * @since 6.0.5\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#asInputStream()",
    "entityType": "method",
    "code": "/**\r\n * Expose this buffer's data as an {@link InputStream}. Both data and read position are\r\n * shared between the returned stream and this data buffer. The underlying buffer will\r\n * <strong>not</strong> be {@linkplain DataBufferUtils#release(DataBuffer) released}\r\n * when the input stream is {@linkplain InputStream#close() closed}.\r\n * @return this data buffer as an input stream\r\n * @see #asInputStream(boolean)\r\n */\r\ndefault InputStream asInputStream() {\r\n    return new DataBufferInputStream(this, false);\r\n}",
    "comment": "\n\t * Expose this buffer's data as an {@link InputStream}. Both data and read position are\n\t * shared between the returned stream and this data buffer. The underlying buffer will\n\t * <strong>not</strong> be {@linkplain DataBufferUtils#release(DataBuffer) released}\n\t * when the input stream is {@linkplain InputStream#close() closed}.\n\t * @return this data buffer as an input stream\n\t * @see #asInputStream(boolean)\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#asInputStream(boolean)",
    "entityType": "method",
    "code": "/**\r\n * Expose this buffer's data as an {@link InputStream}. Both data and read position are\r\n * shared between the returned stream and this data buffer.\r\n * @param releaseOnClose whether the underlying buffer will be\r\n * {@linkplain DataBufferUtils#release(DataBuffer) released} when the input stream is\r\n * {@linkplain InputStream#close() closed}.\r\n * @return this data buffer as an input stream\r\n * @since 5.0.4\r\n */\r\ndefault InputStream asInputStream(boolean releaseOnClose) {\r\n    return new DataBufferInputStream(this, releaseOnClose);\r\n}",
    "comment": "\n\t * Expose this buffer's data as an {@link InputStream}. Both data and read position are\n\t * shared between the returned stream and this data buffer.\n\t * @param releaseOnClose whether the underlying buffer will be\n\t * {@linkplain DataBufferUtils#release(DataBuffer) released} when the input stream is\n\t * {@linkplain InputStream#close() closed}.\n\t * @return this data buffer as an input stream\n\t * @since 5.0.4\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#asOutputStream()",
    "entityType": "method",
    "code": "/**\r\n * Expose this buffer's data as an {@link OutputStream}. Both data and write position are\r\n * shared between the returned stream and this data buffer.\r\n * @return this data buffer as an output stream\r\n */\r\ndefault OutputStream asOutputStream() {\r\n    return new DataBufferOutputStream(this);\r\n}",
    "comment": "\n\t * Expose this buffer's data as an {@link OutputStream}. Both data and write position are\n\t * shared between the returned stream and this data buffer.\n\t * @return this data buffer as an output stream\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#toString(Charset)",
    "entityType": "method",
    "code": "/**\r\n * Return this buffer's data a String using the specified charset. Default implementation\r\n * delegates to {@code toString(readPosition(), readableByteCount(), charset)}.\r\n * @param charset the character set to use\r\n * @return a string representation of all this buffers data\r\n * @since 5.2\r\n */\r\ndefault String toString(Charset charset) {\r\n    Assert.notNull(charset, \"Charset must not be null\");\r\n    return toString(readPosition(), readableByteCount(), charset);\r\n}",
    "comment": "\n\t * Return this buffer's data a String using the specified charset. Default implementation\n\t * delegates to {@code toString(readPosition(), readableByteCount(), charset)}.\n\t * @param charset the character set to use\n\t * @return a string representation of all this buffers data\n\t * @since 5.2\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBuffer#toString(int,int,Charset)",
    "entityType": "method",
    "code": "/**\r\n * Return a part of this buffer's data as a String using the specified charset.\r\n * @param index the index at which to start the string\r\n * @param length the number of bytes to use for the string\r\n * @param charset the charset to use\r\n * @return a string representation of a part of this buffers data\r\n * @since 5.2\r\n */\r\nString toString(int index, int length, Charset charset);",
    "comment": "\n\t * Return a part of this buffer's data as a String using the specified charset.\n\t * @param index the index at which to start the string\n\t * @param length the number of bytes to use for the string\n\t * @param charset the charset to use\n\t * @return a string representation of a part of this buffers data\n\t * @since 5.2\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.ByteBufferIterator",
    "entityType": "class",
    "code": "@Override\r\nvoid close();",
    "comment": "\n\t * A dedicated iterator type that ensures the lifecycle of iterated\n\t * {@link ByteBuffer} elements. This iterator must be used in a\n\t * try-with-resources clause or explicitly {@linkplain #close() closed}.\n\t * @since 6.0.5\n\t * @see DataBuffer#readableByteBuffers()\n\t * @see DataBuffer#writableByteBuffers()\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.ByteBufferIterator#close()",
    "entityType": "method",
    "code": "@Override\r\nvoid close();",
    "comment": ""
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferFactory",
    "entityType": "class",
    "code": "/**\r\n * Allocate a data buffer of a default initial capacity. Depending on the\r\n * underlying implementation and its configuration, this will be heap-based\r\n * or direct buffer.\r\n * @return the allocated buffer\r\n * @deprecated as of 6.0, in favor of {@link #allocateBuffer(int)}\r\n */\r\n@Deprecated(since = \"6.0\")\r\nDataBuffer allocateBuffer();\n/**\r\n * Allocate a data buffer of the given initial capacity. Depending on the\r\n * underlying implementation and its configuration, this will be heap-based\r\n * or direct buffer.\r\n * @param initialCapacity the initial capacity of the buffer to allocate\r\n * @return the allocated buffer\r\n */\r\nDataBuffer allocateBuffer(int initialCapacity);\n/**\r\n * Wrap the given {@link ByteBuffer} in a {@code DataBuffer}. Unlike\r\n * {@linkplain #allocateBuffer(int) allocating}, wrapping does not use new memory.\r\n * @param byteBuffer the NIO byte buffer to wrap\r\n * @return the wrapped buffer\r\n */\r\nDataBuffer wrap(ByteBuffer byteBuffer);\n/**\r\n * Wrap the given {@code byte} array in a {@code DataBuffer}. Unlike\r\n * {@linkplain #allocateBuffer(int) allocating}, wrapping does not use new memory.\r\n * @param bytes the byte array to wrap\r\n * @return the wrapped buffer\r\n */\r\nDataBuffer wrap(byte[] bytes);\n/**\r\n * Return a new {@code DataBuffer} composed of the {@code dataBuffers} elements joined together.\r\n * Depending on the implementation, the returned buffer may be a single buffer containing all\r\n * data of the provided buffers, or it may be a true composite that contains references to the\r\n * buffers.\r\n * <p>Note that the given data buffers do <strong>not</strong> have to be released, as they are\r\n * released as part of the returned composite.\r\n * @param dataBuffers the data buffers to be composed\r\n * @return a buffer that is composed of the {@code dataBuffers} argument\r\n * @since 5.0.3\r\n */\r\nDataBuffer join(List<? extends DataBuffer> dataBuffers);\n/**\r\n * Indicates whether this factory allocates direct buffers (i.e. non-heap,\r\n * native memory).\r\n * @return {@code true} if this factory allocates direct buffers;\r\n * {@code false} otherwise\r\n * @since 6.0\r\n */\r\nboolean isDirect();",
    "comment": "\n * A factory for {@link DataBuffer DataBuffers}, allowing for allocation and\n * wrapping of data buffers.\n *\n * @author Arjen Poutsma\n * @since 5.0\n * @see DataBuffer\n "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferFactory#allocateBuffer()",
    "entityType": "method",
    "code": "/**\r\n * Allocate a data buffer of a default initial capacity. Depending on the\r\n * underlying implementation and its configuration, this will be heap-based\r\n * or direct buffer.\r\n * @return the allocated buffer\r\n * @deprecated as of 6.0, in favor of {@link #allocateBuffer(int)}\r\n */\r\n@Deprecated(since = \"6.0\")\r\nDataBuffer allocateBuffer();",
    "comment": "\n\t * Allocate a data buffer of a default initial capacity. Depending on the\n\t * underlying implementation and its configuration, this will be heap-based\n\t * or direct buffer.\n\t * @return the allocated buffer\n\t * @deprecated as of 6.0, in favor of {@link #allocateBuffer(int)}\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferFactory#allocateBuffer(int)",
    "entityType": "method",
    "code": "/**\r\n * Allocate a data buffer of the given initial capacity. Depending on the\r\n * underlying implementation and its configuration, this will be heap-based\r\n * or direct buffer.\r\n * @param initialCapacity the initial capacity of the buffer to allocate\r\n * @return the allocated buffer\r\n */\r\nDataBuffer allocateBuffer(int initialCapacity);",
    "comment": "\n\t * Allocate a data buffer of the given initial capacity. Depending on the\n\t * underlying implementation and its configuration, this will be heap-based\n\t * or direct buffer.\n\t * @param initialCapacity the initial capacity of the buffer to allocate\n\t * @return the allocated buffer\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferFactory#wrap(ByteBuffer)",
    "entityType": "method",
    "code": "/**\r\n * Wrap the given {@link ByteBuffer} in a {@code DataBuffer}. Unlike\r\n * {@linkplain #allocateBuffer(int) allocating}, wrapping does not use new memory.\r\n * @param byteBuffer the NIO byte buffer to wrap\r\n * @return the wrapped buffer\r\n */\r\nDataBuffer wrap(ByteBuffer byteBuffer);",
    "comment": "\n\t * Wrap the given {@link ByteBuffer} in a {@code DataBuffer}. Unlike\n\t * {@linkplain #allocateBuffer(int) allocating}, wrapping does not use new memory.\n\t * @param byteBuffer the NIO byte buffer to wrap\n\t * @return the wrapped buffer\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferFactory#wrap(byte[])",
    "entityType": "method",
    "code": "/**\r\n * Wrap the given {@code byte} array in a {@code DataBuffer}. Unlike\r\n * {@linkplain #allocateBuffer(int) allocating}, wrapping does not use new memory.\r\n * @param bytes the byte array to wrap\r\n * @return the wrapped buffer\r\n */\r\nDataBuffer wrap(byte[] bytes);",
    "comment": "\n\t * Wrap the given {@code byte} array in a {@code DataBuffer}. Unlike\n \t * {@linkplain #allocateBuffer(int) allocating}, wrapping does not use new memory.\n\t * @param bytes the byte array to wrap\n\t * @return the wrapped buffer\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferFactory#join(List<? extends DataBuffer>)",
    "entityType": "method",
    "code": "/**\r\n * Return a new {@code DataBuffer} composed of the {@code dataBuffers} elements joined together.\r\n * Depending on the implementation, the returned buffer may be a single buffer containing all\r\n * data of the provided buffers, or it may be a true composite that contains references to the\r\n * buffers.\r\n * <p>Note that the given data buffers do <strong>not</strong> have to be released, as they are\r\n * released as part of the returned composite.\r\n * @param dataBuffers the data buffers to be composed\r\n * @return a buffer that is composed of the {@code dataBuffers} argument\r\n * @since 5.0.3\r\n */\r\nDataBuffer join(List<? extends DataBuffer> dataBuffers);",
    "comment": "\n\t * Return a new {@code DataBuffer} composed of the {@code dataBuffers} elements joined together.\n\t * Depending on the implementation, the returned buffer may be a single buffer containing all\n\t * data of the provided buffers, or it may be a true composite that contains references to the\n\t * buffers.\n\t * <p>Note that the given data buffers do <strong>not</strong> have to be released, as they are\n\t * released as part of the returned composite.\n\t * @param dataBuffers the data buffers to be composed\n\t * @return a buffer that is composed of the {@code dataBuffers} argument\n\t * @since 5.0.3\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferFactory#isDirect()",
    "entityType": "method",
    "code": "/**\r\n * Indicates whether this factory allocates direct buffers (i.e. non-heap,\r\n * native memory).\r\n * @return {@code true} if this factory allocates direct buffers;\r\n * {@code false} otherwise\r\n * @since 6.0\r\n */\r\nboolean isDirect();",
    "comment": "\n\t * Indicates whether this factory allocates direct buffers (i.e. non-heap,\n\t * native memory).\n\t * @return {@code true} if this factory allocates direct buffers;\n\t * {@code false} otherwise\n\t * @since 6.0\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferInputStream",
    "entityType": "class",
    "code": "private final DataBuffer dataBuffer;\nprivate final int end;\nprivate final boolean releaseOnClose;\nprivate boolean closed;\nprivate int mark;\npublic DataBufferInputStream(DataBuffer dataBuffer, boolean releaseOnClose) {\r\n    Assert.notNull(dataBuffer, \"DataBuffer must not be null\");\r\n    this.dataBuffer = dataBuffer;\r\n    int start = this.dataBuffer.readPosition();\r\n    this.end = start + this.dataBuffer.readableByteCount();\r\n    this.mark = start;\r\n    this.releaseOnClose = releaseOnClose;\r\n}\n@Override\r\npublic int read() throws IOException {\r\n    checkClosed();\r\n    if (available() == 0) {\r\n        return -1;\r\n    }\r\n    return this.dataBuffer.read() & 0xFF;\r\n}\n@Override\r\npublic int read(byte[] b, int off, int len) throws IOException {\r\n    checkClosed();\r\n    int available = available();\r\n    if (available == 0) {\r\n        return -1;\r\n    }\r\n    len = Math.min(available, len);\r\n    this.dataBuffer.read(b, off, len);\r\n    return len;\r\n}\n@Override\r\npublic boolean markSupported() {\r\n    return true;\r\n}\n@Override\r\npublic void mark(int readLimit) {\r\n    Assert.isTrue(readLimit > 0, \"readLimit must be greater than 0\");\r\n    this.mark = this.dataBuffer.readPosition();\r\n}\n@Override\r\npublic int available() {\r\n    return Math.max(0, this.end - this.dataBuffer.readPosition());\r\n}\n@Override\r\npublic void reset() {\r\n    this.dataBuffer.readPosition(this.mark);\r\n}\n@Override\r\npublic void close() {\r\n    if (this.closed) {\r\n        return;\r\n    }\r\n    if (this.releaseOnClose) {\r\n        DataBufferUtils.release(this.dataBuffer);\r\n    }\r\n    this.closed = true;\r\n}\nprivate void checkClosed() throws IOException {\r\n    if (this.closed) {\r\n        throw new IOException(\"DataBufferInputStream is closed\");\r\n    }\r\n}",
    "comment": "\n * An {@link InputStream} that reads from a {@link DataBuffer}.\n *\n * @author Arjen Poutsma\n * @since 6.0\n * @see DataBuffer#asInputStream(boolean)\n "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferInputStream#read()",
    "entityType": "method",
    "code": "@Override\r\npublic int read() throws IOException {\r\n    checkClosed();\r\n    if (available() == 0) {\r\n        return -1;\r\n    }\r\n    return this.dataBuffer.read() & 0xFF;\r\n}",
    "comment": ""
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferInputStream#read(byte[],int,int)",
    "entityType": "method",
    "code": "@Override\r\npublic int read(byte[] b, int off, int len) throws IOException {\r\n    checkClosed();\r\n    int available = available();\r\n    if (available == 0) {\r\n        return -1;\r\n    }\r\n    len = Math.min(available, len);\r\n    this.dataBuffer.read(b, off, len);\r\n    return len;\r\n}",
    "comment": ""
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferInputStream#markSupported()",
    "entityType": "method",
    "code": "@Override\r\npublic boolean markSupported() {\r\n    return true;\r\n}",
    "comment": ""
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferInputStream#mark(int)",
    "entityType": "method",
    "code": "@Override\r\npublic void mark(int readLimit) {\r\n    Assert.isTrue(readLimit > 0, \"readLimit must be greater than 0\");\r\n    this.mark = this.dataBuffer.readPosition();\r\n}",
    "comment": ""
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferInputStream#available()",
    "entityType": "method",
    "code": "@Override\r\npublic int available() {\r\n    return Math.max(0, this.end - this.dataBuffer.readPosition());\r\n}",
    "comment": ""
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferInputStream#reset()",
    "entityType": "method",
    "code": "@Override\r\npublic void reset() {\r\n    this.dataBuffer.readPosition(this.mark);\r\n}",
    "comment": ""
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferInputStream#close()",
    "entityType": "method",
    "code": "@Override\r\npublic void close() {\r\n    if (this.closed) {\r\n        return;\r\n    }\r\n    if (this.releaseOnClose) {\r\n        DataBufferUtils.release(this.dataBuffer);\r\n    }\r\n    this.closed = true;\r\n}",
    "comment": ""
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferInputStream#checkClosed()",
    "entityType": "method",
    "code": "private void checkClosed() throws IOException {\r\n    if (this.closed) {\r\n        throw new IOException(\"DataBufferInputStream is closed\");\r\n    }\r\n}",
    "comment": ""
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferLimitException",
    "entityType": "class",
    "code": "public DataBufferLimitException(String message) {\r\n    super(message);\r\n}",
    "comment": "\n * Exception that indicates the cumulative number of bytes consumed from a\n * stream of {@link DataBuffer DataBuffer}'s exceeded some pre-configured limit.\n * This can be raised when data buffers are cached and aggregated, for example,\n * {@link DataBufferUtils#join}. Or it could also be raised when data buffers\n * have been released but a parsed representation is being aggregated, for example, async\n * parsing with Jackson, SSE parsing and aggregating lines per event.\n *\n * @author Rossen Stoyanchev\n * @since 5.1.11\n "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferOutputStream",
    "entityType": "class",
    "code": "private final DataBuffer dataBuffer;\nprivate boolean closed;\npublic DataBufferOutputStream(DataBuffer dataBuffer) {\r\n    Assert.notNull(dataBuffer, \"DataBuffer must not be null\");\r\n    this.dataBuffer = dataBuffer;\r\n}\n@Override\r\npublic void write(int b) throws IOException {\r\n    checkClosed();\r\n    this.dataBuffer.ensureWritable(1);\r\n    this.dataBuffer.write((byte) b);\r\n}\n@Override\r\npublic void write(byte[] b, int off, int len) throws IOException {\r\n    checkClosed();\r\n    if (len > 0) {\r\n        this.dataBuffer.ensureWritable(len);\r\n        this.dataBuffer.write(b, off, len);\r\n    }\r\n}\n@Override\r\npublic void close() {\r\n    if (this.closed) {\r\n        return;\r\n    }\r\n    this.closed = true;\r\n}\nprivate void checkClosed() throws IOException {\r\n    if (this.closed) {\r\n        throw new IOException(\"DataBufferOutputStream is closed\");\r\n    }\r\n}",
    "comment": "\n * An {@link OutputStream} that writes to a {@link DataBuffer}.\n *\n * @author Arjen Poutsma\n * @since 6.0\n * @see DataBuffer#asOutputStream()\n "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferOutputStream#write(int)",
    "entityType": "method",
    "code": "@Override\r\npublic void write(int b) throws IOException {\r\n    checkClosed();\r\n    this.dataBuffer.ensureWritable(1);\r\n    this.dataBuffer.write((byte) b);\r\n}",
    "comment": ""
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferOutputStream#write(byte[],int,int)",
    "entityType": "method",
    "code": "@Override\r\npublic void write(byte[] b, int off, int len) throws IOException {\r\n    checkClosed();\r\n    if (len > 0) {\r\n        this.dataBuffer.ensureWritable(len);\r\n        this.dataBuffer.write(b, off, len);\r\n    }\r\n}",
    "comment": ""
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferOutputStream#close()",
    "entityType": "method",
    "code": "@Override\r\npublic void close() {\r\n    if (this.closed) {\r\n        return;\r\n    }\r\n    this.closed = true;\r\n}",
    "comment": ""
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferOutputStream#checkClosed()",
    "entityType": "method",
    "code": "private void checkClosed() throws IOException {\r\n    if (this.closed) {\r\n        throw new IOException(\"DataBufferOutputStream is closed\");\r\n    }\r\n}",
    "comment": ""
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils",
    "entityType": "class",
    "code": "private static final Log logger = LogFactory.getLog(DataBufferUtils.class);\nprivate static final Consumer<DataBuffer> RELEASE_CONSUMER = DataBufferUtils::release;\n//---------------------------------------------------------------------\r\n// Reading\r\n//---------------------------------------------------------------------\r\n/**\r\n * Obtain an {@link InputStream} from the given supplier, and read it into a\r\n * {@code Flux} of {@code DataBuffer}s. Closes the input stream when the\r\n * Flux is terminated.\r\n * @param inputStreamSupplier the supplier for the input stream to read from\r\n * @param bufferFactory the factory to create data buffers with\r\n * @param bufferSize the maximum size of the data buffers\r\n * @return a Flux of data buffers read from the given channel\r\n */\r\npublic static Flux<DataBuffer> readInputStream(Callable<InputStream> inputStreamSupplier, DataBufferFactory bufferFactory, int bufferSize) {\r\n    Assert.notNull(inputStreamSupplier, \"'inputStreamSupplier' must not be null\");\r\n    return readByteChannel(() -> Channels.newChannel(inputStreamSupplier.call()), bufferFactory, bufferSize);\r\n}\n/**\r\n * Obtain a {@link ReadableByteChannel} from the given supplier, and read\r\n * it into a {@code Flux} of {@code DataBuffer}s. Closes the channel when\r\n * the Flux is terminated.\r\n * @param channelSupplier the supplier for the channel to read from\r\n * @param bufferFactory the factory to create data buffers with\r\n * @param bufferSize the maximum size of the data buffers\r\n * @return a Flux of data buffers read from the given channel\r\n */\r\npublic static Flux<DataBuffer> readByteChannel(Callable<ReadableByteChannel> channelSupplier, DataBufferFactory bufferFactory, int bufferSize) {\r\n    Assert.notNull(channelSupplier, \"'channelSupplier' must not be null\");\r\n    Assert.notNull(bufferFactory, \"'bufferFactory' must not be null\");\r\n    Assert.isTrue(bufferSize > 0, \"'bufferSize' must be > 0\");\r\n    return Flux.using(channelSupplier, channel -> Flux.generate(new ReadableByteChannelGenerator(channel, bufferFactory, bufferSize)), DataBufferUtils::closeChannel);\r\n    // No doOnDiscard as operators used do not cache\r\n}\n/**\r\n * Obtain a {@code AsynchronousFileChannel} from the given supplier, and read\r\n * it into a {@code Flux} of {@code DataBuffer}s. Closes the channel when\r\n * the Flux is terminated.\r\n * @param channelSupplier the supplier for the channel to read from\r\n * @param bufferFactory the factory to create data buffers with\r\n * @param bufferSize the maximum size of the data buffers\r\n * @return a Flux of data buffers read from the given channel\r\n */\r\npublic static Flux<DataBuffer> readAsynchronousFileChannel(Callable<AsynchronousFileChannel> channelSupplier, DataBufferFactory bufferFactory, int bufferSize) {\r\n    return readAsynchronousFileChannel(channelSupplier, 0, bufferFactory, bufferSize);\r\n}\n/**\r\n * Obtain an {@code AsynchronousFileChannel} from the given supplier, and\r\n * read it into a {@code Flux} of {@code DataBuffer}s, starting at the given\r\n * position. Closes the channel when the Flux is terminated.\r\n * @param channelSupplier the supplier for the channel to read from\r\n * @param position the position to start reading from\r\n * @param bufferFactory the factory to create data buffers with\r\n * @param bufferSize the maximum size of the data buffers\r\n * @return a Flux of data buffers read from the given channel\r\n */\r\npublic static Flux<DataBuffer> readAsynchronousFileChannel(Callable<AsynchronousFileChannel> channelSupplier, long position, DataBufferFactory bufferFactory, int bufferSize) {\r\n    Assert.notNull(channelSupplier, \"'channelSupplier' must not be null\");\r\n    Assert.notNull(bufferFactory, \"'bufferFactory' must not be null\");\r\n    Assert.isTrue(position >= 0, \"'position' must be >= 0\");\r\n    Assert.isTrue(bufferSize > 0, \"'bufferSize' must be > 0\");\r\n    Flux<DataBuffer> flux = Flux.using(channelSupplier, channel -> Flux.create(sink -> {\r\n        ReadCompletionHandler handler = new ReadCompletionHandler(channel, sink, position, bufferFactory, bufferSize);\r\n        sink.onCancel(handler::cancel);\r\n        sink.onRequest(handler::request);\r\n    }), channel -> {\r\n        // Do not close channel from here, rather wait for the current read callback\r\n        // and then complete after releasing the DataBuffer.\r\n    });\r\n    return flux.doOnDiscard(DataBuffer.class, DataBufferUtils::release);\r\n}\n/**\r\n * Read bytes from the given file {@code Path} into a {@code Flux} of {@code DataBuffer}s.\r\n * The method ensures that the file is closed when the flux is terminated.\r\n * @param path the path to read bytes from\r\n * @param bufferFactory the factory to create data buffers with\r\n * @param bufferSize the maximum size of the data buffers\r\n * @return a Flux of data buffers read from the given channel\r\n * @since 5.2\r\n */\r\npublic static Flux<DataBuffer> read(Path path, DataBufferFactory bufferFactory, int bufferSize, OpenOption... options) {\r\n    Assert.notNull(path, \"Path must not be null\");\r\n    Assert.notNull(bufferFactory, \"DataBufferFactory must not be null\");\r\n    Assert.isTrue(bufferSize > 0, \"'bufferSize' must be > 0\");\r\n    if (options.length > 0) {\r\n        for (OpenOption option : options) {\r\n            Assert.isTrue(!(option == StandardOpenOption.APPEND || option == StandardOpenOption.WRITE), () -> \"'\" + option + \"' not allowed\");\r\n        }\r\n    }\r\n    return readAsynchronousFileChannel(() -> AsynchronousFileChannel.open(path, options), bufferFactory, bufferSize);\r\n}\n/**\r\n * Read the given {@code Resource} into a {@code Flux} of {@code DataBuffer}s.\r\n * <p>If the resource is a file, it is read into an\r\n * {@code AsynchronousFileChannel} and turned to {@code Flux} via\r\n * {@link #readAsynchronousFileChannel(Callable, DataBufferFactory, int)} or else\r\n * fall back to {@link #readByteChannel(Callable, DataBufferFactory, int)}.\r\n * Closes the channel when the flux is terminated.\r\n * @param resource the resource to read from\r\n * @param bufferFactory the factory to create data buffers with\r\n * @param bufferSize the maximum size of the data buffers\r\n * @return a Flux of data buffers read from the given channel\r\n */\r\npublic static Flux<DataBuffer> read(Resource resource, DataBufferFactory bufferFactory, int bufferSize) {\r\n    return read(resource, 0, bufferFactory, bufferSize);\r\n}\n/**\r\n * Read the given {@code Resource} into a {@code Flux} of {@code DataBuffer}s\r\n * starting at the given position.\r\n * <p>If the resource is a file, it is read into an\r\n * {@code AsynchronousFileChannel} and turned to {@code Flux} via\r\n * {@link #readAsynchronousFileChannel(Callable, DataBufferFactory, int)} or else\r\n * fall back on {@link #readByteChannel(Callable, DataBufferFactory, int)}.\r\n * Closes the channel when the flux is terminated.\r\n * @param resource the resource to read from\r\n * @param position the position to start reading from\r\n * @param bufferFactory the factory to create data buffers with\r\n * @param bufferSize the maximum size of the data buffers\r\n * @return a Flux of data buffers read from the given channel\r\n */\r\npublic static Flux<DataBuffer> read(Resource resource, long position, DataBufferFactory bufferFactory, int bufferSize) {\r\n    try {\r\n        if (resource.isFile()) {\r\n            File file = resource.getFile();\r\n            return readAsynchronousFileChannel(() -> AsynchronousFileChannel.open(file.toPath(), StandardOpenOption.READ), position, bufferFactory, bufferSize);\r\n        }\r\n    } catch (IOException ignore) {\r\n        // fallback to resource.readableChannel(), below\r\n    }\r\n    Flux<DataBuffer> result = readByteChannel(resource::readableChannel, bufferFactory, bufferSize);\r\n    return position == 0 ? result : skipUntilByteCount(result, position);\r\n}\n//---------------------------------------------------------------------\r\n// Writing\r\n//---------------------------------------------------------------------\r\n/**\r\n * Write the given stream of {@link DataBuffer DataBuffers} to the given\r\n * {@code OutputStream}. Does <strong>not</strong> close the output stream\r\n * when the flux is terminated, and does <strong>not</strong>\r\n * {@linkplain #release(DataBuffer) release} the data buffers in the source.\r\n * If releasing is required, then subscribe to the returned {@code Flux}\r\n * with a {@link #releaseConsumer()}.\r\n * <p>Note that the writing process does not start until the returned\r\n * {@code Flux} is subscribed to.\r\n * @param source the stream of data buffers to be written\r\n * @param outputStream the output stream to write to\r\n * @return a Flux containing the same buffers as in {@code source}, that\r\n * starts the writing process when subscribed to, and that publishes any\r\n * writing errors and the completion signal\r\n */\r\npublic static Flux<DataBuffer> write(Publisher<DataBuffer> source, OutputStream outputStream) {\r\n    Assert.notNull(source, \"'source' must not be null\");\r\n    Assert.notNull(outputStream, \"'outputStream' must not be null\");\r\n    WritableByteChannel channel = Channels.newChannel(outputStream);\r\n    return write(source, channel);\r\n}\n/**\r\n * Write the given stream of {@link DataBuffer DataBuffers} to the given\r\n * {@code WritableByteChannel}. Does <strong>not</strong> close the channel\r\n * when the flux is terminated, and does <strong>not</strong>\r\n * {@linkplain #release(DataBuffer) release} the data buffers in the source.\r\n * If releasing is required, then subscribe to the returned {@code Flux}\r\n * with a {@link #releaseConsumer()}.\r\n * <p>Note that the writing process does not start until the returned\r\n * {@code Flux} is subscribed to.\r\n * @param source the stream of data buffers to be written\r\n * @param channel the channel to write to\r\n * @return a Flux containing the same buffers as in {@code source}, that\r\n * starts the writing process when subscribed to, and that publishes any\r\n * writing errors and the completion signal\r\n */\r\npublic static Flux<DataBuffer> write(Publisher<DataBuffer> source, WritableByteChannel channel) {\r\n    Assert.notNull(source, \"'source' must not be null\");\r\n    Assert.notNull(channel, \"'channel' must not be null\");\r\n    Flux<DataBuffer> flux = Flux.from(source);\r\n    return Flux.create(sink -> {\r\n        WritableByteChannelSubscriber subscriber = new WritableByteChannelSubscriber(sink, channel);\r\n        sink.onDispose(subscriber);\r\n        flux.subscribe(subscriber);\r\n    });\r\n}\n/**\r\n * Write the given stream of {@link DataBuffer DataBuffers} to the given\r\n * {@code AsynchronousFileChannel}. Does <strong>not</strong> close the\r\n * channel when the flux is terminated, and does <strong>not</strong>\r\n * {@linkplain #release(DataBuffer) release} the data buffers in the source.\r\n * If releasing is required, then subscribe to the returned {@code Flux}\r\n * with a {@link #releaseConsumer()}.\r\n * <p>Note that the writing process does not start until the returned\r\n * {@code Flux} is subscribed to.\r\n * @param source the stream of data buffers to be written\r\n * @param channel the channel to write to\r\n * @return a Flux containing the same buffers as in {@code source}, that\r\n * starts the writing process when subscribed to, and that publishes any\r\n * writing errors and the completion signal\r\n * @since 5.0.10\r\n */\r\npublic static Flux<DataBuffer> write(Publisher<DataBuffer> source, AsynchronousFileChannel channel) {\r\n    return write(source, channel, 0);\r\n}\n/**\r\n * Write the given stream of {@link DataBuffer DataBuffers} to the given\r\n * {@code AsynchronousFileChannel}. Does <strong>not</strong> close the channel\r\n * when the flux is terminated, and does <strong>not</strong>\r\n * {@linkplain #release(DataBuffer) release} the data buffers in the source.\r\n * If releasing is required, then subscribe to the returned {@code Flux} with a\r\n * {@link #releaseConsumer()}.\r\n * <p>Note that the writing process does not start until the returned\r\n * {@code Flux} is subscribed to.\r\n * @param source the stream of data buffers to be written\r\n * @param channel the channel to write to\r\n * @param position the file position where writing is to begin; must be non-negative\r\n * @return a flux containing the same buffers as in {@code source}, that\r\n * starts the writing process when subscribed to, and that publishes any\r\n * writing errors and the completion signal\r\n */\r\npublic static Flux<DataBuffer> write(Publisher<? extends DataBuffer> source, AsynchronousFileChannel channel, long position) {\r\n    Assert.notNull(source, \"'source' must not be null\");\r\n    Assert.notNull(channel, \"'channel' must not be null\");\r\n    Assert.isTrue(position >= 0, \"'position' must be >= 0\");\r\n    Flux<DataBuffer> flux = Flux.from(source);\r\n    return Flux.create(sink -> {\r\n        WriteCompletionHandler handler = new WriteCompletionHandler(sink, channel, position);\r\n        sink.onDispose(handler);\r\n        flux.subscribe(handler);\r\n    });\r\n}\n/**\r\n * Write the given stream of {@link DataBuffer DataBuffers} to the given\r\n * file {@link Path}. The optional {@code options} parameter specifies\r\n * how the file is created or opened (defaults to\r\n * {@link StandardOpenOption#CREATE CREATE},\r\n * {@link StandardOpenOption#TRUNCATE_EXISTING TRUNCATE_EXISTING}, and\r\n * {@link StandardOpenOption#WRITE WRITE}).\r\n * @param source the stream of data buffers to be written\r\n * @param destination the path to the file\r\n * @param options the options specifying how the file is opened\r\n * @return a {@link Mono} that indicates completion or error\r\n * @since 5.2\r\n */\r\npublic static Mono<Void> write(Publisher<DataBuffer> source, Path destination, OpenOption... options) {\r\n    Assert.notNull(source, \"Source must not be null\");\r\n    Assert.notNull(destination, \"Destination must not be null\");\r\n    Set<OpenOption> optionSet = checkWriteOptions(options);\r\n    return Mono.create(sink -> {\r\n        try {\r\n            AsynchronousFileChannel channel = AsynchronousFileChannel.open(destination, optionSet, null);\r\n            sink.onDispose(() -> closeChannel(channel));\r\n            write(source, channel).subscribe(DataBufferUtils::release, sink::error, sink::success, Context.of(sink.contextView()));\r\n        } catch (IOException ex) {\r\n            sink.error(ex);\r\n        }\r\n    });\r\n}\nprivate static Set<OpenOption> checkWriteOptions(OpenOption[] options) {\r\n    int length = options.length;\r\n    Set<OpenOption> result = CollectionUtils.newHashSet(length > 0 ? length : 2);\r\n    if (length == 0) {\r\n        result.add(StandardOpenOption.CREATE);\r\n        result.add(StandardOpenOption.TRUNCATE_EXISTING);\r\n    } else {\r\n        for (OpenOption opt : options) {\r\n            if (opt == StandardOpenOption.READ) {\r\n                throw new IllegalArgumentException(\"READ not allowed\");\r\n            }\r\n            result.add(opt);\r\n        }\r\n    }\r\n    result.add(StandardOpenOption.WRITE);\r\n    return result;\r\n}\nstatic void closeChannel(@Nullable Channel channel) {\r\n    if (channel != null && channel.isOpen()) {\r\n        try {\r\n            channel.close();\r\n        } catch (IOException ignored) ;\r\n    }\r\n}\n/**\r\n * Create a new {@code Publisher<DataBuffer>} based on bytes written to a\r\n * {@code OutputStream}.\r\n * <ul>\r\n * <li>The parameter {@code outputStreamConsumer} is invoked once per\r\n * subscription of the returned {@code Publisher}, when the first\r\n * item is\r\n * {@linkplain Subscription#request(long) requested}.</li>\r\n * <li>{@link OutputStream#write(byte[], int, int) OutputStream.write()}\r\n * invocations made by {@code outputStreamConsumer} are buffered until they\r\n * exceed the default chunk size of 1024, or when the stream is\r\n * {@linkplain OutputStream#flush() flushed} and then result in a\r\n * {@linkplain Subscriber#onNext(Object) published} item\r\n * if there is {@linkplain Subscription#request(long) demand}.</li>\r\n * <li>If there is <em>no demand</em>, {@code OutputStream.write()} will block\r\n * until there is.</li>\r\n * <li>If the subscription is {@linkplain Subscription#cancel() cancelled},\r\n * {@code OutputStream.write()} will throw a {@code IOException}.</li>\r\n * <li>The subscription is\r\n * {@linkplain Subscriber#onComplete() completed} when\r\n * {@code outputStreamHandler} completes.</li>\r\n * <li>Any exceptions thrown from {@code outputStreamHandler} will\r\n * be dispatched to the {@linkplain Subscriber#onError(Throwable) Subscriber}.\r\n * </ul>\r\n * @param consumer invoked when the first buffer is requested\r\n * @param executor used to invoke the {@code outputStreamHandler}\r\n * @return a {@code Publisher<DataBuffer>} based on bytes written by\r\n * {@code outputStreamHandler}\r\n * @since 6.1\r\n */\r\npublic static Publisher<DataBuffer> outputStreamPublisher(Consumer<OutputStream> consumer, DataBufferFactory bufferFactory, Executor executor) {\r\n    return new OutputStreamPublisher<>(consumer::accept, new DataBufferMapper(bufferFactory), executor, null);\r\n}\n/**\r\n * Variant of {@link #outputStreamPublisher(Consumer, DataBufferFactory, Executor)}\r\n * providing control over the chunk sizes to be produced by the publisher.\r\n * @since 6.1\r\n */\r\npublic static Publisher<DataBuffer> outputStreamPublisher(Consumer<OutputStream> consumer, DataBufferFactory bufferFactory, Executor executor, int chunkSize) {\r\n    return new OutputStreamPublisher<>(consumer::accept, new DataBufferMapper(bufferFactory), executor, chunkSize);\r\n}\n/**\r\n * Subscribe to given {@link Publisher} of {@code DataBuffer}s, and return an\r\n * {@link InputStream} to consume the byte content with.\r\n * <p>Byte buffers are stored in a queue. The {@code demand} constructor value\r\n * determines the number of buffers requested initially. When storage falls\r\n * below a {@code (demand - (demand >> 2))} limit, a request is made to refill\r\n * the queue.\r\n * <p>The {@code InputStream} terminates after an onError or onComplete signal,\r\n * and stored buffers are read. If the {@code InputStream} is closed,\r\n * the {@link Flow.Subscription} is cancelled, and stored buffers released.\r\n * @param publisher the source of {@code DataBuffer}s\r\n * @param demand the number of buffers to request initially, and buffer\r\n * internally on an ongoing basis.\r\n * @return an {@link InputStream} backed by the {@link Publisher}\r\n */\r\npublic static <T extends DataBuffer> InputStream subscriberInputStream(Publisher<T> publisher, int demand) {\r\n    Assert.notNull(publisher, \"Publisher must not be null\");\r\n    Assert.isTrue(demand > 0, \"maxBufferCount must be > 0\");\r\n    SubscriberInputStream subscriber = new SubscriberInputStream(demand);\r\n    publisher.subscribe(subscriber);\r\n    return subscriber;\r\n}\n//---------------------------------------------------------------------\r\n// Various\r\n//---------------------------------------------------------------------\r\n/**\r\n * Relay buffers from the given {@link Publisher} until the total\r\n * {@linkplain DataBuffer#readableByteCount() byte count} reaches\r\n * the given maximum byte count, or until the publisher is complete.\r\n * @param publisher the publisher to filter\r\n * @param maxByteCount the maximum byte count\r\n * @return a flux whose maximum byte count is {@code maxByteCount}\r\n */\r\n@SuppressWarnings(\"unchecked\")\r\npublic static <T extends DataBuffer> Flux<T> takeUntilByteCount(Publisher<T> publisher, long maxByteCount) {\r\n    Assert.notNull(publisher, \"Publisher must not be null\");\r\n    Assert.isTrue(maxByteCount >= 0, \"'maxByteCount' must be >= 0\");\r\n    return Flux.defer(() -> {\r\n        AtomicLong countDown = new AtomicLong(maxByteCount);\r\n        return Flux.from(publisher).map(buffer -> {\r\n            long remainder = countDown.addAndGet(-buffer.readableByteCount());\r\n            if (remainder < 0) {\r\n                int index = buffer.readableByteCount() + (int) remainder;\r\n                DataBuffer split = buffer.split(index);\r\n                release(buffer);\r\n                return (T) split;\r\n            } else {\r\n                return buffer;\r\n            }\r\n        }).takeUntil(buffer -> countDown.get() <= 0);\r\n    });\r\n    // No doOnDiscard as operators used do not cache (and drop) buffers\r\n}\n/**\r\n * Skip buffers from the given {@link Publisher} until the total\r\n * {@linkplain DataBuffer#readableByteCount() byte count} reaches\r\n * the given maximum byte count, or until the publisher is complete.\r\n * @param publisher the publisher to filter\r\n * @param maxByteCount the maximum byte count\r\n * @return a flux with the remaining part of the given publisher\r\n */\r\npublic static <T extends DataBuffer> Flux<T> skipUntilByteCount(Publisher<T> publisher, long maxByteCount) {\r\n    Assert.notNull(publisher, \"Publisher must not be null\");\r\n    Assert.isTrue(maxByteCount >= 0, \"'maxByteCount' must be >= 0\");\r\n    return Flux.defer(() -> {\r\n        AtomicLong countDown = new AtomicLong(maxByteCount);\r\n        return Flux.from(publisher).skipUntil(buffer -> {\r\n            long remainder = countDown.addAndGet(-buffer.readableByteCount());\r\n            return remainder < 0;\r\n        }).map(buffer -> {\r\n            long remainder = countDown.get();\r\n            if (remainder < 0) {\r\n                countDown.set(0);\r\n                int start = buffer.readableByteCount() + (int) remainder;\r\n                DataBuffer split = buffer.split(start);\r\n                release(split);\r\n                return buffer;\r\n            } else {\r\n                return buffer;\r\n            }\r\n        });\r\n    }).doOnDiscard(DataBuffer.class, DataBufferUtils::release);\r\n}\n/**\r\n * Retain the given data buffer, if it is a {@link PooledDataBuffer}.\r\n * @param dataBuffer the data buffer to retain\r\n * @return the retained buffer\r\n */\r\n@SuppressWarnings(\"unchecked\")\r\npublic static <T extends DataBuffer> T retain(T dataBuffer) {\r\n    if (dataBuffer instanceof PooledDataBuffer pooledDataBuffer) {\r\n        return (T) pooledDataBuffer.retain();\r\n    } else {\r\n        return dataBuffer;\r\n    }\r\n}\n/**\r\n * Associate the given hint with the data buffer if it is a pooled buffer\r\n * and supports leak tracking.\r\n * @param dataBuffer the data buffer to attach the hint to\r\n * @param hint the hint to attach\r\n * @return the input buffer\r\n * @since 5.3.2\r\n */\r\n@SuppressWarnings(\"unchecked\")\r\npublic static <T extends DataBuffer> T touch(T dataBuffer, Object hint) {\r\n    if (dataBuffer instanceof TouchableDataBuffer touchableDataBuffer) {\r\n        return (T) touchableDataBuffer.touch(hint);\r\n    } else {\r\n        return dataBuffer;\r\n    }\r\n}\n/**\r\n * Release the given data buffer. If it is a {@link PooledDataBuffer} and\r\n * has been {@linkplain PooledDataBuffer#isAllocated() allocated}, this\r\n * method will call {@link PooledDataBuffer#release()}. If it is a\r\n * {@link CloseableDataBuffer}, this method will call\r\n * {@link CloseableDataBuffer#close()}.\r\n * @param dataBuffer the data buffer to release\r\n * @return {@code true} if the buffer was released; {@code false} otherwise.\r\n */\r\npublic static boolean release(@Nullable DataBuffer dataBuffer) {\r\n    if (dataBuffer instanceof PooledDataBuffer pooledDataBuffer) {\r\n        if (pooledDataBuffer.isAllocated()) {\r\n            try {\r\n                return pooledDataBuffer.release();\r\n            } catch (IllegalStateException ex) {\r\n                if (logger.isDebugEnabled()) {\r\n                    logger.debug(\"Failed to release PooledDataBuffer: \" + dataBuffer, ex);\r\n                }\r\n                return false;\r\n            }\r\n        }\r\n    } else if (dataBuffer instanceof CloseableDataBuffer closeableDataBuffer) {\r\n        try {\r\n            closeableDataBuffer.close();\r\n            return true;\r\n        } catch (IllegalStateException ex) {\r\n            if (logger.isDebugEnabled()) {\r\n                logger.debug(\"Failed to release CloseableDataBuffer \" + dataBuffer, ex);\r\n            }\r\n            return false;\r\n        }\r\n    }\r\n    return false;\r\n}\n/**\r\n * Return a consumer that calls {@link #release(DataBuffer)} on all\r\n * passed data buffers.\r\n */\r\npublic static Consumer<DataBuffer> releaseConsumer() {\r\n    return RELEASE_CONSUMER;\r\n}\n/**\r\n * Return a new {@code DataBuffer} composed of joining together the given\r\n * {@code dataBuffers} elements. Depending on the {@link DataBuffer} type,\r\n * the returned buffer may be a single buffer containing all data of the\r\n * provided buffers, or it may be a zero-copy, composite with references to\r\n * the given buffers.\r\n * <p>If {@code dataBuffers} produces an error or if there is a cancel\r\n * signal, then all accumulated buffers will be\r\n * {@linkplain #release(DataBuffer) released}.\r\n * <p>Note that the given data buffers do <strong>not</strong> have to be\r\n * released. They will be released as part of the returned composite.\r\n * @param dataBuffers the data buffers that are to be composed\r\n * @return a buffer that is composed of the {@code dataBuffers} argument\r\n * @since 5.0.3\r\n */\r\npublic static Mono<DataBuffer> join(Publisher<? extends DataBuffer> dataBuffers) {\r\n    return join(dataBuffers, -1);\r\n}\n/**\r\n * Variant of {@link #join(Publisher)} that behaves the same way up until\r\n * the specified max number of bytes to buffer. Once the limit is exceeded,\r\n * {@link DataBufferLimitException} is raised.\r\n * @param buffers the data buffers that are to be composed\r\n * @param maxByteCount the max number of bytes to buffer, or -1 for unlimited\r\n * @return a buffer with the aggregated content, possibly an empty Mono if\r\n * the max number of bytes to buffer is exceeded.\r\n * @throws DataBufferLimitException if maxByteCount is exceeded\r\n * @since 5.1.11\r\n */\r\n@SuppressWarnings({ \"rawtypes\", \"unchecked\" })\r\npublic static Mono<DataBuffer> join(Publisher<? extends DataBuffer> buffers, int maxByteCount) {\r\n    Assert.notNull(buffers, \"'buffers' must not be null\");\r\n    if (buffers instanceof Mono mono) {\r\n        return mono;\r\n    }\r\n    return Flux.from(buffers).collect(() -> new LimitedDataBufferList(maxByteCount), LimitedDataBufferList::add).filter(list -> !list.isEmpty()).map(list -> list.get(0).factory().join(list)).doOnDiscard(DataBuffer.class, DataBufferUtils::release);\r\n}\n/**\r\n * Return a {@link Matcher} for the given delimiter.\r\n * The matcher can be used to find the delimiters in a stream of data buffers.\r\n * @param delimiter the delimiter bytes to find\r\n * @return the matcher\r\n * @since 5.2\r\n */\r\npublic static Matcher matcher(byte[] delimiter) {\r\n    return createMatcher(delimiter);\r\n}\n/**\r\n * Return a {@link Matcher} for the given delimiters.\r\n * The matcher can be used to find the delimiters in a stream of data buffers.\r\n * @param delimiters the delimiters bytes to find\r\n * @return the matcher\r\n * @since 5.2\r\n */\r\npublic static Matcher matcher(byte[]... delimiters) {\r\n    Assert.isTrue(delimiters.length > 0, \"Delimiters must not be empty\");\r\n    return (delimiters.length == 1 ? createMatcher(delimiters[0]) : new CompositeMatcher(delimiters));\r\n}\nprivate static NestedMatcher createMatcher(byte[] delimiter) {\r\n    // extract length due to Eclipse IDE compiler error in switch expression\r\n    int length = delimiter.length;\r\n    Assert.isTrue(length > 0, \"Delimiter must not be empty\");\r\n    return switch(length) {\r\n        case 1 ->\r\n            (delimiter[0] == 10 ? SingleByteMatcher.NEWLINE_MATCHER : new SingleByteMatcher(delimiter));\r\n        case 2 ->\r\n            new TwoByteMatcher(delimiter);\r\n        default ->\r\n            new KnuthMorrisPrattMatcher(delimiter);\r\n    };\r\n}\n/**\r\n * Contract to find delimiter(s) against one or more data buffers that can\r\n * be passed one at a time to the {@link #match(DataBuffer)} method.\r\n *\r\n * @since 5.2\r\n * @see #match(DataBuffer)\r\n */\r\npublic interface Matcher {\r\n\r\n    /**\r\n     * Find the first matching delimiter and return the index of the last\r\n     * byte of the delimiter, or {@code -1} if not found.\r\n     */\r\n    int match(DataBuffer dataBuffer);\r\n\r\n    /**\r\n     * Return the delimiter from the last invocation of {@link #match(DataBuffer)}.\r\n     */\r\n    byte[] delimiter();\r\n\r\n    /**\r\n     * Reset the state of this matcher.\r\n     */\r\n    void reset();\r\n}\n/**\r\n * Matcher that supports searching for multiple delimiters.\r\n */\r\nprivate static class CompositeMatcher implements Matcher {\r\n\r\n    private static final byte[] NO_DELIMITER = new byte[0];\r\n\r\n    private final NestedMatcher[] matchers;\r\n\r\n    byte[] longestDelimiter = NO_DELIMITER;\r\n\r\n    CompositeMatcher(byte[][] delimiters) {\r\n        this.matchers = initMatchers(delimiters);\r\n    }\r\n\r\n    private static NestedMatcher[] initMatchers(byte[][] delimiters) {\r\n        NestedMatcher[] matchers = new NestedMatcher[delimiters.length];\r\n        for (int i = 0; i < delimiters.length; i++) {\r\n            matchers[i] = createMatcher(delimiters[i]);\r\n        }\r\n        return matchers;\r\n    }\r\n\r\n    @Override\r\n    public int match(DataBuffer dataBuffer) {\r\n        this.longestDelimiter = NO_DELIMITER;\r\n        for (int pos = dataBuffer.readPosition(); pos < dataBuffer.writePosition(); pos++) {\r\n            byte b = dataBuffer.getByte(pos);\r\n            for (NestedMatcher matcher : this.matchers) {\r\n                if (matcher.match(b) && matcher.delimiter().length > this.longestDelimiter.length) {\r\n                    this.longestDelimiter = matcher.delimiter();\r\n                }\r\n            }\r\n            if (this.longestDelimiter != NO_DELIMITER) {\r\n                reset();\r\n                return pos;\r\n            }\r\n        }\r\n        return -1;\r\n    }\r\n\r\n    @Override\r\n    public byte[] delimiter() {\r\n        Assert.state(this.longestDelimiter != NO_DELIMITER, \"'delimiter' not set\");\r\n        return this.longestDelimiter;\r\n    }\r\n\r\n    @Override\r\n    public void reset() {\r\n        for (NestedMatcher matcher : this.matchers) {\r\n            matcher.reset();\r\n        }\r\n    }\r\n}\n/**\r\n * Matcher that can be nested within {@link CompositeMatcher} where multiple\r\n * matchers advance together using the same index, one byte at a time.\r\n */\r\nprivate interface NestedMatcher extends Matcher {\r\n\r\n    /**\r\n     * Perform a match against the next byte of the stream and return true\r\n     * if the delimiter is fully matched.\r\n     */\r\n    boolean match(byte b);\r\n}\n/**\r\n * Matcher for a single byte delimiter.\r\n */\r\nprivate static class SingleByteMatcher implements NestedMatcher {\r\n\r\n    static final SingleByteMatcher NEWLINE_MATCHER = new SingleByteMatcher(new byte[] { 10 });\r\n\r\n    private final byte[] delimiter;\r\n\r\n    SingleByteMatcher(byte[] delimiter) {\r\n        Assert.isTrue(delimiter.length == 1, \"Expected a 1 byte delimiter\");\r\n        this.delimiter = delimiter;\r\n    }\r\n\r\n    @Override\r\n    public int match(DataBuffer dataBuffer) {\r\n        for (int pos = dataBuffer.readPosition(); pos < dataBuffer.writePosition(); pos++) {\r\n            byte b = dataBuffer.getByte(pos);\r\n            if (match(b)) {\r\n                return pos;\r\n            }\r\n        }\r\n        return -1;\r\n    }\r\n\r\n    @Override\r\n    public boolean match(byte b) {\r\n        return this.delimiter[0] == b;\r\n    }\r\n\r\n    @Override\r\n    public byte[] delimiter() {\r\n        return this.delimiter;\r\n    }\r\n\r\n    @Override\r\n    public void reset() {\r\n    }\r\n}\n/**\r\n * Base class for a {@link NestedMatcher}.\r\n */\r\nprivate abstract static class AbstractNestedMatcher implements NestedMatcher {\r\n\r\n    private final byte[] delimiter;\r\n\r\n    private int matches = 0;\r\n\r\n    protected AbstractNestedMatcher(byte[] delimiter) {\r\n        this.delimiter = delimiter;\r\n    }\r\n\r\n    protected void setMatches(int index) {\r\n        this.matches = index;\r\n    }\r\n\r\n    protected int getMatches() {\r\n        return this.matches;\r\n    }\r\n\r\n    @Override\r\n    public int match(DataBuffer dataBuffer) {\r\n        for (int pos = dataBuffer.readPosition(); pos < dataBuffer.writePosition(); pos++) {\r\n            byte b = dataBuffer.getByte(pos);\r\n            if (match(b)) {\r\n                reset();\r\n                return pos;\r\n            }\r\n        }\r\n        return -1;\r\n    }\r\n\r\n    @Override\r\n    public boolean match(byte b) {\r\n        if (b == this.delimiter[this.matches]) {\r\n            this.matches++;\r\n            return (this.matches == delimiter().length);\r\n        }\r\n        return false;\r\n    }\r\n\r\n    @Override\r\n    public byte[] delimiter() {\r\n        return this.delimiter;\r\n    }\r\n\r\n    @Override\r\n    public void reset() {\r\n        this.matches = 0;\r\n    }\r\n}\n/**\r\n * Matcher with a 2 byte delimiter that does not benefit from a\r\n * Knuth-Morris-Pratt suffix-prefix table.\r\n */\r\nprivate static class TwoByteMatcher extends AbstractNestedMatcher {\r\n\r\n    protected TwoByteMatcher(byte[] delimiter) {\r\n        super(delimiter);\r\n        Assert.isTrue(delimiter.length == 2, \"Expected a 2-byte delimiter\");\r\n    }\r\n}\n/**\r\n * Implementation of {@link Matcher} that uses the Knuth-Morris-Pratt algorithm.\r\n * @see <a href=\"https://www.nayuki.io/page/knuth-morris-pratt-string-matching\">Knuth-Morris-Pratt string matching</a>\r\n */\r\nprivate static class KnuthMorrisPrattMatcher extends AbstractNestedMatcher {\r\n\r\n    private final int[] table;\r\n\r\n    public KnuthMorrisPrattMatcher(byte[] delimiter) {\r\n        super(delimiter);\r\n        this.table = longestSuffixPrefixTable(delimiter);\r\n    }\r\n\r\n    private static int[] longestSuffixPrefixTable(byte[] delimiter) {\r\n        int[] result = new int[delimiter.length];\r\n        result[0] = 0;\r\n        for (int i = 1; i < delimiter.length; i++) {\r\n            int j = result[i - 1];\r\n            while (j > 0 && delimiter[i] != delimiter[j]) {\r\n                j = result[j - 1];\r\n            }\r\n            if (delimiter[i] == delimiter[j]) {\r\n                j++;\r\n            }\r\n            result[i] = j;\r\n        }\r\n        return result;\r\n    }\r\n\r\n    @Override\r\n    public boolean match(byte b) {\r\n        while (getMatches() > 0 && b != delimiter()[getMatches()]) {\r\n            setMatches(this.table[getMatches() - 1]);\r\n        }\r\n        return super.match(b);\r\n    }\r\n}\nprivate static class ReadableByteChannelGenerator implements Consumer<SynchronousSink<DataBuffer>> {\r\n\r\n    private final ReadableByteChannel channel;\r\n\r\n    private final DataBufferFactory dataBufferFactory;\r\n\r\n    private final int bufferSize;\r\n\r\n    public ReadableByteChannelGenerator(ReadableByteChannel channel, DataBufferFactory dataBufferFactory, int bufferSize) {\r\n        this.channel = channel;\r\n        this.dataBufferFactory = dataBufferFactory;\r\n        this.bufferSize = bufferSize;\r\n    }\r\n\r\n    @Override\r\n    public void accept(SynchronousSink<DataBuffer> sink) {\r\n        int read = -1;\r\n        DataBuffer dataBuffer = this.dataBufferFactory.allocateBuffer(this.bufferSize);\r\n        try {\r\n            try (DataBuffer.ByteBufferIterator iterator = dataBuffer.writableByteBuffers()) {\r\n                Assert.state(iterator.hasNext(), \"No ByteBuffer available\");\r\n                ByteBuffer byteBuffer = iterator.next();\r\n                read = this.channel.read(byteBuffer);\r\n            }\r\n            if (read >= 0) {\r\n                dataBuffer.writePosition(read);\r\n                sink.next(dataBuffer);\r\n            } else {\r\n                sink.complete();\r\n            }\r\n        } catch (IOException ex) {\r\n            sink.error(ex);\r\n        } finally {\r\n            if (read == -1) {\r\n                release(dataBuffer);\r\n            }\r\n        }\r\n    }\r\n}\nprivate static class ReadCompletionHandler implements CompletionHandler<Integer, ReadCompletionHandler.Attachment> {\r\n\r\n    private final AsynchronousFileChannel channel;\r\n\r\n    private final FluxSink<DataBuffer> sink;\r\n\r\n    private final DataBufferFactory dataBufferFactory;\r\n\r\n    private final int bufferSize;\r\n\r\n    private final AtomicLong position;\r\n\r\n    private final AtomicReference<State> state = new AtomicReference<>(State.IDLE);\r\n\r\n    public ReadCompletionHandler(AsynchronousFileChannel channel, FluxSink<DataBuffer> sink, long position, DataBufferFactory dataBufferFactory, int bufferSize) {\r\n        this.channel = channel;\r\n        this.sink = sink;\r\n        this.position = new AtomicLong(position);\r\n        this.dataBufferFactory = dataBufferFactory;\r\n        this.bufferSize = bufferSize;\r\n    }\r\n\r\n    /**\r\n     * Invoked when Reactive Streams consumer signals demand.\r\n     */\r\n    public void request(long n) {\r\n        tryRead();\r\n    }\r\n\r\n    /**\r\n     * Invoked when Reactive Streams consumer cancels.\r\n     */\r\n    public void cancel() {\r\n        this.state.getAndSet(State.DISPOSED);\r\n        // According java.nio.channels.AsynchronousChannel \"if an I/O operation is outstanding\r\n        // on the channel and the channel's close method is invoked, then the I/O operation\r\n        // fails with the exception AsynchronousCloseException\". That should invoke the failed\r\n        // callback below and the current DataBuffer should be released.\r\n        closeChannel(this.channel);\r\n    }\r\n\r\n    private void tryRead() {\r\n        if (this.sink.requestedFromDownstream() > 0 && this.state.compareAndSet(State.IDLE, State.READING)) {\r\n            read();\r\n        }\r\n    }\r\n\r\n    private void read() {\r\n        DataBuffer dataBuffer = this.dataBufferFactory.allocateBuffer(this.bufferSize);\r\n        DataBuffer.ByteBufferIterator iterator = dataBuffer.writableByteBuffers();\r\n        Assert.state(iterator.hasNext(), \"No ByteBuffer available\");\r\n        ByteBuffer byteBuffer = iterator.next();\r\n        Attachment attachment = new Attachment(dataBuffer, iterator);\r\n        this.channel.read(byteBuffer, this.position.get(), attachment, this);\r\n    }\r\n\r\n    @Override\r\n    public void completed(Integer read, Attachment attachment) {\r\n        attachment.iterator().close();\r\n        DataBuffer dataBuffer = attachment.dataBuffer();\r\n        if (this.state.get() == State.DISPOSED) {\r\n            release(dataBuffer);\r\n            closeChannel(this.channel);\r\n            return;\r\n        }\r\n        if (read == -1) {\r\n            release(dataBuffer);\r\n            closeChannel(this.channel);\r\n            this.state.set(State.DISPOSED);\r\n            this.sink.complete();\r\n            return;\r\n        }\r\n        this.position.addAndGet(read);\r\n        dataBuffer.writePosition(read);\r\n        this.sink.next(dataBuffer);\r\n        // Stay in READING mode if there is demand\r\n        if (this.sink.requestedFromDownstream() > 0) {\r\n            read();\r\n            return;\r\n        }\r\n        // Release READING mode and then try again in case of concurrent \"request\"\r\n        if (this.state.compareAndSet(State.READING, State.IDLE)) {\r\n            tryRead();\r\n        }\r\n    }\r\n\r\n    @Override\r\n    public void failed(Throwable ex, Attachment attachment) {\r\n        attachment.iterator().close();\r\n        release(attachment.dataBuffer());\r\n        closeChannel(this.channel);\r\n        this.state.set(State.DISPOSED);\r\n        this.sink.error(ex);\r\n    }\r\n\r\n    private enum State {\r\n\r\n        IDLE, READING, DISPOSED\r\n    }\r\n\r\n    private record Attachment(DataBuffer dataBuffer, DataBuffer.ByteBufferIterator iterator) {\r\n    }\r\n}\nprivate static class WritableByteChannelSubscriber extends BaseSubscriber<DataBuffer> {\r\n\r\n    private final FluxSink<DataBuffer> sink;\r\n\r\n    private final WritableByteChannel channel;\r\n\r\n    public WritableByteChannelSubscriber(FluxSink<DataBuffer> sink, WritableByteChannel channel) {\r\n        this.sink = sink;\r\n        this.channel = channel;\r\n    }\r\n\r\n    @Override\r\n    protected void hookOnSubscribe(Subscription subscription) {\r\n        request(1);\r\n    }\r\n\r\n    @Override\r\n    protected void hookOnNext(DataBuffer dataBuffer) {\r\n        try {\r\n            try (DataBuffer.ByteBufferIterator iterator = dataBuffer.readableByteBuffers()) {\r\n                ByteBuffer byteBuffer = iterator.next();\r\n                while (byteBuffer.hasRemaining()) {\r\n                    this.channel.write(byteBuffer);\r\n                }\r\n            }\r\n            this.sink.next(dataBuffer);\r\n            request(1);\r\n        } catch (IOException ex) {\r\n            this.sink.next(dataBuffer);\r\n            this.sink.error(ex);\r\n        }\r\n    }\r\n\r\n    @Override\r\n    protected void hookOnError(Throwable throwable) {\r\n        this.sink.error(throwable);\r\n    }\r\n\r\n    @Override\r\n    protected void hookOnComplete() {\r\n        this.sink.complete();\r\n    }\r\n\r\n    @Override\r\n    public Context currentContext() {\r\n        return Context.of(this.sink.contextView());\r\n    }\r\n}\nprivate static class WriteCompletionHandler extends BaseSubscriber<DataBuffer> implements CompletionHandler<Integer, WriteCompletionHandler.Attachment> {\r\n\r\n    private final FluxSink<DataBuffer> sink;\r\n\r\n    private final AsynchronousFileChannel channel;\r\n\r\n    private final AtomicBoolean writing = new AtomicBoolean();\r\n\r\n    private final AtomicBoolean completed = new AtomicBoolean();\r\n\r\n    private final AtomicReference<Throwable> error = new AtomicReference<>();\r\n\r\n    private final AtomicLong position;\r\n\r\n    public WriteCompletionHandler(FluxSink<DataBuffer> sink, AsynchronousFileChannel channel, long position) {\r\n        this.sink = sink;\r\n        this.channel = channel;\r\n        this.position = new AtomicLong(position);\r\n    }\r\n\r\n    @Override\r\n    protected void hookOnSubscribe(Subscription subscription) {\r\n        request(1);\r\n    }\r\n\r\n    @Override\r\n    protected void hookOnNext(DataBuffer dataBuffer) {\r\n        DataBuffer.ByteBufferIterator iterator = dataBuffer.readableByteBuffers();\r\n        if (iterator.hasNext()) {\r\n            ByteBuffer byteBuffer = iterator.next();\r\n            long pos = this.position.get();\r\n            Attachment attachment = new Attachment(byteBuffer, dataBuffer, iterator);\r\n            this.writing.set(true);\r\n            this.channel.write(byteBuffer, pos, attachment, this);\r\n        }\r\n    }\r\n\r\n    @Override\r\n    protected void hookOnError(Throwable throwable) {\r\n        this.error.set(throwable);\r\n        if (!this.writing.get()) {\r\n            this.sink.error(throwable);\r\n        }\r\n    }\r\n\r\n    @Override\r\n    protected void hookOnComplete() {\r\n        this.completed.set(true);\r\n        if (!this.writing.get()) {\r\n            this.sink.complete();\r\n        }\r\n    }\r\n\r\n    @Override\r\n    public void completed(Integer written, Attachment attachment) {\r\n        DataBuffer.ByteBufferIterator iterator = attachment.iterator();\r\n        iterator.close();\r\n        long pos = this.position.addAndGet(written);\r\n        ByteBuffer byteBuffer = attachment.byteBuffer();\r\n        if (byteBuffer.hasRemaining()) {\r\n            this.channel.write(byteBuffer, pos, attachment, this);\r\n        } else if (iterator.hasNext()) {\r\n            ByteBuffer next = iterator.next();\r\n            this.channel.write(next, pos, attachment, this);\r\n        } else {\r\n            this.sink.next(attachment.dataBuffer());\r\n            this.writing.set(false);\r\n            Throwable throwable = this.error.get();\r\n            if (throwable != null) {\r\n                this.sink.error(throwable);\r\n            } else if (this.completed.get()) {\r\n                this.sink.complete();\r\n            } else {\r\n                request(1);\r\n            }\r\n        }\r\n    }\r\n\r\n    @Override\r\n    public void failed(Throwable ex, Attachment attachment) {\r\n        attachment.iterator().close();\r\n        this.sink.next(attachment.dataBuffer());\r\n        this.writing.set(false);\r\n        this.sink.error(ex);\r\n    }\r\n\r\n    @Override\r\n    public Context currentContext() {\r\n        return Context.of(this.sink.contextView());\r\n    }\r\n\r\n    private record Attachment(ByteBuffer byteBuffer, DataBuffer dataBuffer, DataBuffer.ByteBufferIterator iterator) {\r\n    }\r\n}\nprivate static final class DataBufferMapper implements OutputStreamPublisher.ByteMapper<DataBuffer> {\r\n\r\n    private final DataBufferFactory bufferFactory;\r\n\r\n    private DataBufferMapper(DataBufferFactory bufferFactory) {\r\n        this.bufferFactory = bufferFactory;\r\n    }\r\n\r\n    @Override\r\n    public DataBuffer map(int b) {\r\n        DataBuffer buffer = this.bufferFactory.allocateBuffer(1);\r\n        buffer.write((byte) b);\r\n        return buffer;\r\n    }\r\n\r\n    @Override\r\n    public DataBuffer map(byte[] b, int off, int len) {\r\n        DataBuffer buffer = this.bufferFactory.allocateBuffer(len);\r\n        buffer.write(b, off, len);\r\n        return buffer;\r\n    }\r\n}",
    "comment": "\n * Utility class for working with {@link DataBuffer DataBuffers}.\n *\n * @author Arjen Poutsma\n * @author Brian Clozel\n * @since 5.0\n "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#readInputStream(Callable<InputStream>,DataBufferFactory,int)",
    "entityType": "method",
    "code": "//---------------------------------------------------------------------\r\n// Reading\r\n//---------------------------------------------------------------------\r\n/**\r\n * Obtain an {@link InputStream} from the given supplier, and read it into a\r\n * {@code Flux} of {@code DataBuffer}s. Closes the input stream when the\r\n * Flux is terminated.\r\n * @param inputStreamSupplier the supplier for the input stream to read from\r\n * @param bufferFactory the factory to create data buffers with\r\n * @param bufferSize the maximum size of the data buffers\r\n * @return a Flux of data buffers read from the given channel\r\n */\r\npublic static Flux<DataBuffer> readInputStream(Callable<InputStream> inputStreamSupplier, DataBufferFactory bufferFactory, int bufferSize) {\r\n    Assert.notNull(inputStreamSupplier, \"'inputStreamSupplier' must not be null\");\r\n    return readByteChannel(() -> Channels.newChannel(inputStreamSupplier.call()), bufferFactory, bufferSize);\r\n}",
    "comment": "\n\t * Obtain an {@link InputStream} from the given supplier, and read it into a\n\t * {@code Flux} of {@code DataBuffer}s. Closes the input stream when the\n\t * Flux is terminated.\n\t * @param inputStreamSupplier the supplier for the input stream to read from\n\t * @param bufferFactory the factory to create data buffers with\n\t * @param bufferSize the maximum size of the data buffers\n\t * @return a Flux of data buffers read from the given channel\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#readByteChannel(Callable<ReadableByteChannel>,DataBufferFactory,int)",
    "entityType": "method",
    "code": "/**\r\n * Obtain a {@link ReadableByteChannel} from the given supplier, and read\r\n * it into a {@code Flux} of {@code DataBuffer}s. Closes the channel when\r\n * the Flux is terminated.\r\n * @param channelSupplier the supplier for the channel to read from\r\n * @param bufferFactory the factory to create data buffers with\r\n * @param bufferSize the maximum size of the data buffers\r\n * @return a Flux of data buffers read from the given channel\r\n */\r\npublic static Flux<DataBuffer> readByteChannel(Callable<ReadableByteChannel> channelSupplier, DataBufferFactory bufferFactory, int bufferSize) {\r\n    Assert.notNull(channelSupplier, \"'channelSupplier' must not be null\");\r\n    Assert.notNull(bufferFactory, \"'bufferFactory' must not be null\");\r\n    Assert.isTrue(bufferSize > 0, \"'bufferSize' must be > 0\");\r\n    return Flux.using(channelSupplier, channel -> Flux.generate(new ReadableByteChannelGenerator(channel, bufferFactory, bufferSize)), DataBufferUtils::closeChannel);\r\n    // No doOnDiscard as operators used do not cache\r\n}",
    "comment": "\n\t * Obtain a {@link ReadableByteChannel} from the given supplier, and read\n\t * it into a {@code Flux} of {@code DataBuffer}s. Closes the channel when\n\t * the Flux is terminated.\n\t * @param channelSupplier the supplier for the channel to read from\n\t * @param bufferFactory the factory to create data buffers with\n\t * @param bufferSize the maximum size of the data buffers\n\t * @return a Flux of data buffers read from the given channel\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#readAsynchronousFileChannel(Callable<AsynchronousFileChannel>,DataBufferFactory,int)",
    "entityType": "method",
    "code": "/**\r\n * Obtain a {@code AsynchronousFileChannel} from the given supplier, and read\r\n * it into a {@code Flux} of {@code DataBuffer}s. Closes the channel when\r\n * the Flux is terminated.\r\n * @param channelSupplier the supplier for the channel to read from\r\n * @param bufferFactory the factory to create data buffers with\r\n * @param bufferSize the maximum size of the data buffers\r\n * @return a Flux of data buffers read from the given channel\r\n */\r\npublic static Flux<DataBuffer> readAsynchronousFileChannel(Callable<AsynchronousFileChannel> channelSupplier, DataBufferFactory bufferFactory, int bufferSize) {\r\n    return readAsynchronousFileChannel(channelSupplier, 0, bufferFactory, bufferSize);\r\n}",
    "comment": "\n\t * Obtain a {@code AsynchronousFileChannel} from the given supplier, and read\n\t * it into a {@code Flux} of {@code DataBuffer}s. Closes the channel when\n\t * the Flux is terminated.\n\t * @param channelSupplier the supplier for the channel to read from\n\t * @param bufferFactory the factory to create data buffers with\n\t * @param bufferSize the maximum size of the data buffers\n\t * @return a Flux of data buffers read from the given channel\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#readAsynchronousFileChannel(Callable<AsynchronousFileChannel>,long,DataBufferFactory,int)",
    "entityType": "method",
    "code": "/**\r\n * Obtain an {@code AsynchronousFileChannel} from the given supplier, and\r\n * read it into a {@code Flux} of {@code DataBuffer}s, starting at the given\r\n * position. Closes the channel when the Flux is terminated.\r\n * @param channelSupplier the supplier for the channel to read from\r\n * @param position the position to start reading from\r\n * @param bufferFactory the factory to create data buffers with\r\n * @param bufferSize the maximum size of the data buffers\r\n * @return a Flux of data buffers read from the given channel\r\n */\r\npublic static Flux<DataBuffer> readAsynchronousFileChannel(Callable<AsynchronousFileChannel> channelSupplier, long position, DataBufferFactory bufferFactory, int bufferSize) {\r\n    Assert.notNull(channelSupplier, \"'channelSupplier' must not be null\");\r\n    Assert.notNull(bufferFactory, \"'bufferFactory' must not be null\");\r\n    Assert.isTrue(position >= 0, \"'position' must be >= 0\");\r\n    Assert.isTrue(bufferSize > 0, \"'bufferSize' must be > 0\");\r\n    Flux<DataBuffer> flux = Flux.using(channelSupplier, channel -> Flux.create(sink -> {\r\n        ReadCompletionHandler handler = new ReadCompletionHandler(channel, sink, position, bufferFactory, bufferSize);\r\n        sink.onCancel(handler::cancel);\r\n        sink.onRequest(handler::request);\r\n    }), channel -> {\r\n        // Do not close channel from here, rather wait for the current read callback\r\n        // and then complete after releasing the DataBuffer.\r\n    });\r\n    return flux.doOnDiscard(DataBuffer.class, DataBufferUtils::release);\r\n}",
    "comment": "\n\t * Obtain an {@code AsynchronousFileChannel} from the given supplier, and\n\t * read it into a {@code Flux} of {@code DataBuffer}s, starting at the given\n\t * position. Closes the channel when the Flux is terminated.\n\t * @param channelSupplier the supplier for the channel to read from\n\t * @param position the position to start reading from\n\t * @param bufferFactory the factory to create data buffers with\n\t * @param bufferSize the maximum size of the data buffers\n\t * @return a Flux of data buffers read from the given channel\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#read(Path,DataBufferFactory,int,OpenOption)",
    "entityType": "method",
    "code": "/**\r\n * Read bytes from the given file {@code Path} into a {@code Flux} of {@code DataBuffer}s.\r\n * The method ensures that the file is closed when the flux is terminated.\r\n * @param path the path to read bytes from\r\n * @param bufferFactory the factory to create data buffers with\r\n * @param bufferSize the maximum size of the data buffers\r\n * @return a Flux of data buffers read from the given channel\r\n * @since 5.2\r\n */\r\npublic static Flux<DataBuffer> read(Path path, DataBufferFactory bufferFactory, int bufferSize, OpenOption... options) {\r\n    Assert.notNull(path, \"Path must not be null\");\r\n    Assert.notNull(bufferFactory, \"DataBufferFactory must not be null\");\r\n    Assert.isTrue(bufferSize > 0, \"'bufferSize' must be > 0\");\r\n    if (options.length > 0) {\r\n        for (OpenOption option : options) {\r\n            Assert.isTrue(!(option == StandardOpenOption.APPEND || option == StandardOpenOption.WRITE), () -> \"'\" + option + \"' not allowed\");\r\n        }\r\n    }\r\n    return readAsynchronousFileChannel(() -> AsynchronousFileChannel.open(path, options), bufferFactory, bufferSize);\r\n}",
    "comment": "\n\t * Read bytes from the given file {@code Path} into a {@code Flux} of {@code DataBuffer}s.\n\t * The method ensures that the file is closed when the flux is terminated.\n\t * @param path the path to read bytes from\n\t * @param bufferFactory the factory to create data buffers with\n\t * @param bufferSize the maximum size of the data buffers\n\t * @return a Flux of data buffers read from the given channel\n\t * @since 5.2\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#read(Resource,DataBufferFactory,int)",
    "entityType": "method",
    "code": "/**\r\n * Read the given {@code Resource} into a {@code Flux} of {@code DataBuffer}s.\r\n * <p>If the resource is a file, it is read into an\r\n * {@code AsynchronousFileChannel} and turned to {@code Flux} via\r\n * {@link #readAsynchronousFileChannel(Callable, DataBufferFactory, int)} or else\r\n * fall back to {@link #readByteChannel(Callable, DataBufferFactory, int)}.\r\n * Closes the channel when the flux is terminated.\r\n * @param resource the resource to read from\r\n * @param bufferFactory the factory to create data buffers with\r\n * @param bufferSize the maximum size of the data buffers\r\n * @return a Flux of data buffers read from the given channel\r\n */\r\npublic static Flux<DataBuffer> read(Resource resource, DataBufferFactory bufferFactory, int bufferSize) {\r\n    return read(resource, 0, bufferFactory, bufferSize);\r\n}",
    "comment": "\n\t * Read the given {@code Resource} into a {@code Flux} of {@code DataBuffer}s.\n\t * <p>If the resource is a file, it is read into an\n\t * {@code AsynchronousFileChannel} and turned to {@code Flux} via\n\t * {@link #readAsynchronousFileChannel(Callable, DataBufferFactory, int)} or else\n\t * fall back to {@link #readByteChannel(Callable, DataBufferFactory, int)}.\n\t * Closes the channel when the flux is terminated.\n\t * @param resource the resource to read from\n\t * @param bufferFactory the factory to create data buffers with\n\t * @param bufferSize the maximum size of the data buffers\n\t * @return a Flux of data buffers read from the given channel\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#read(Resource,long,DataBufferFactory,int)",
    "entityType": "method",
    "code": "/**\r\n * Read the given {@code Resource} into a {@code Flux} of {@code DataBuffer}s\r\n * starting at the given position.\r\n * <p>If the resource is a file, it is read into an\r\n * {@code AsynchronousFileChannel} and turned to {@code Flux} via\r\n * {@link #readAsynchronousFileChannel(Callable, DataBufferFactory, int)} or else\r\n * fall back on {@link #readByteChannel(Callable, DataBufferFactory, int)}.\r\n * Closes the channel when the flux is terminated.\r\n * @param resource the resource to read from\r\n * @param position the position to start reading from\r\n * @param bufferFactory the factory to create data buffers with\r\n * @param bufferSize the maximum size of the data buffers\r\n * @return a Flux of data buffers read from the given channel\r\n */\r\npublic static Flux<DataBuffer> read(Resource resource, long position, DataBufferFactory bufferFactory, int bufferSize) {\r\n    try {\r\n        if (resource.isFile()) {\r\n            File file = resource.getFile();\r\n            return readAsynchronousFileChannel(() -> AsynchronousFileChannel.open(file.toPath(), StandardOpenOption.READ), position, bufferFactory, bufferSize);\r\n        }\r\n    } catch (IOException ignore) {\r\n        // fallback to resource.readableChannel(), below\r\n    }\r\n    Flux<DataBuffer> result = readByteChannel(resource::readableChannel, bufferFactory, bufferSize);\r\n    return position == 0 ? result : skipUntilByteCount(result, position);\r\n}",
    "comment": "\n\t * Read the given {@code Resource} into a {@code Flux} of {@code DataBuffer}s\n\t * starting at the given position.\n\t * <p>If the resource is a file, it is read into an\n\t * {@code AsynchronousFileChannel} and turned to {@code Flux} via\n\t * {@link #readAsynchronousFileChannel(Callable, DataBufferFactory, int)} or else\n\t * fall back on {@link #readByteChannel(Callable, DataBufferFactory, int)}.\n\t * Closes the channel when the flux is terminated.\n\t * @param resource the resource to read from\n\t * @param position the position to start reading from\n\t * @param bufferFactory the factory to create data buffers with\n\t * @param bufferSize the maximum size of the data buffers\n\t * @return a Flux of data buffers read from the given channel\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#write(Publisher<DataBuffer>,OutputStream)",
    "entityType": "method",
    "code": "//---------------------------------------------------------------------\r\n// Writing\r\n//---------------------------------------------------------------------\r\n/**\r\n * Write the given stream of {@link DataBuffer DataBuffers} to the given\r\n * {@code OutputStream}. Does <strong>not</strong> close the output stream\r\n * when the flux is terminated, and does <strong>not</strong>\r\n * {@linkplain #release(DataBuffer) release} the data buffers in the source.\r\n * If releasing is required, then subscribe to the returned {@code Flux}\r\n * with a {@link #releaseConsumer()}.\r\n * <p>Note that the writing process does not start until the returned\r\n * {@code Flux} is subscribed to.\r\n * @param source the stream of data buffers to be written\r\n * @param outputStream the output stream to write to\r\n * @return a Flux containing the same buffers as in {@code source}, that\r\n * starts the writing process when subscribed to, and that publishes any\r\n * writing errors and the completion signal\r\n */\r\npublic static Flux<DataBuffer> write(Publisher<DataBuffer> source, OutputStream outputStream) {\r\n    Assert.notNull(source, \"'source' must not be null\");\r\n    Assert.notNull(outputStream, \"'outputStream' must not be null\");\r\n    WritableByteChannel channel = Channels.newChannel(outputStream);\r\n    return write(source, channel);\r\n}",
    "comment": "\n\t * Write the given stream of {@link DataBuffer DataBuffers} to the given\n\t * {@code OutputStream}. Does <strong>not</strong> close the output stream\n\t * when the flux is terminated, and does <strong>not</strong>\n\t * {@linkplain #release(DataBuffer) release} the data buffers in the source.\n\t * If releasing is required, then subscribe to the returned {@code Flux}\n\t * with a {@link #releaseConsumer()}.\n\t * <p>Note that the writing process does not start until the returned\n\t * {@code Flux} is subscribed to.\n\t * @param source the stream of data buffers to be written\n\t * @param outputStream the output stream to write to\n\t * @return a Flux containing the same buffers as in {@code source}, that\n\t * starts the writing process when subscribed to, and that publishes any\n\t * writing errors and the completion signal\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#write(Publisher<DataBuffer>,WritableByteChannel)",
    "entityType": "method",
    "code": "/**\r\n * Write the given stream of {@link DataBuffer DataBuffers} to the given\r\n * {@code WritableByteChannel}. Does <strong>not</strong> close the channel\r\n * when the flux is terminated, and does <strong>not</strong>\r\n * {@linkplain #release(DataBuffer) release} the data buffers in the source.\r\n * If releasing is required, then subscribe to the returned {@code Flux}\r\n * with a {@link #releaseConsumer()}.\r\n * <p>Note that the writing process does not start until the returned\r\n * {@code Flux} is subscribed to.\r\n * @param source the stream of data buffers to be written\r\n * @param channel the channel to write to\r\n * @return a Flux containing the same buffers as in {@code source}, that\r\n * starts the writing process when subscribed to, and that publishes any\r\n * writing errors and the completion signal\r\n */\r\npublic static Flux<DataBuffer> write(Publisher<DataBuffer> source, WritableByteChannel channel) {\r\n    Assert.notNull(source, \"'source' must not be null\");\r\n    Assert.notNull(channel, \"'channel' must not be null\");\r\n    Flux<DataBuffer> flux = Flux.from(source);\r\n    return Flux.create(sink -> {\r\n        WritableByteChannelSubscriber subscriber = new WritableByteChannelSubscriber(sink, channel);\r\n        sink.onDispose(subscriber);\r\n        flux.subscribe(subscriber);\r\n    });\r\n}",
    "comment": "\n\t * Write the given stream of {@link DataBuffer DataBuffers} to the given\n\t * {@code WritableByteChannel}. Does <strong>not</strong> close the channel\n\t * when the flux is terminated, and does <strong>not</strong>\n\t * {@linkplain #release(DataBuffer) release} the data buffers in the source.\n\t * If releasing is required, then subscribe to the returned {@code Flux}\n\t * with a {@link #releaseConsumer()}.\n\t * <p>Note that the writing process does not start until the returned\n\t * {@code Flux} is subscribed to.\n\t * @param source the stream of data buffers to be written\n\t * @param channel the channel to write to\n\t * @return a Flux containing the same buffers as in {@code source}, that\n\t * starts the writing process when subscribed to, and that publishes any\n\t * writing errors and the completion signal\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#write(Publisher<DataBuffer>,AsynchronousFileChannel)",
    "entityType": "method",
    "code": "/**\r\n * Write the given stream of {@link DataBuffer DataBuffers} to the given\r\n * {@code AsynchronousFileChannel}. Does <strong>not</strong> close the\r\n * channel when the flux is terminated, and does <strong>not</strong>\r\n * {@linkplain #release(DataBuffer) release} the data buffers in the source.\r\n * If releasing is required, then subscribe to the returned {@code Flux}\r\n * with a {@link #releaseConsumer()}.\r\n * <p>Note that the writing process does not start until the returned\r\n * {@code Flux} is subscribed to.\r\n * @param source the stream of data buffers to be written\r\n * @param channel the channel to write to\r\n * @return a Flux containing the same buffers as in {@code source}, that\r\n * starts the writing process when subscribed to, and that publishes any\r\n * writing errors and the completion signal\r\n * @since 5.0.10\r\n */\r\npublic static Flux<DataBuffer> write(Publisher<DataBuffer> source, AsynchronousFileChannel channel) {\r\n    return write(source, channel, 0);\r\n}",
    "comment": "\n\t * Write the given stream of {@link DataBuffer DataBuffers} to the given\n\t * {@code AsynchronousFileChannel}. Does <strong>not</strong> close the\n\t * channel when the flux is terminated, and does <strong>not</strong>\n\t * {@linkplain #release(DataBuffer) release} the data buffers in the source.\n\t * If releasing is required, then subscribe to the returned {@code Flux}\n\t * with a {@link #releaseConsumer()}.\n\t * <p>Note that the writing process does not start until the returned\n\t * {@code Flux} is subscribed to.\n\t * @param source the stream of data buffers to be written\n\t * @param channel the channel to write to\n\t * @return a Flux containing the same buffers as in {@code source}, that\n\t * starts the writing process when subscribed to, and that publishes any\n\t * writing errors and the completion signal\n\t * @since 5.0.10\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#write(Publisher<? extends DataBuffer>,AsynchronousFileChannel,long)",
    "entityType": "method",
    "code": "/**\r\n * Write the given stream of {@link DataBuffer DataBuffers} to the given\r\n * {@code AsynchronousFileChannel}. Does <strong>not</strong> close the channel\r\n * when the flux is terminated, and does <strong>not</strong>\r\n * {@linkplain #release(DataBuffer) release} the data buffers in the source.\r\n * If releasing is required, then subscribe to the returned {@code Flux} with a\r\n * {@link #releaseConsumer()}.\r\n * <p>Note that the writing process does not start until the returned\r\n * {@code Flux} is subscribed to.\r\n * @param source the stream of data buffers to be written\r\n * @param channel the channel to write to\r\n * @param position the file position where writing is to begin; must be non-negative\r\n * @return a flux containing the same buffers as in {@code source}, that\r\n * starts the writing process when subscribed to, and that publishes any\r\n * writing errors and the completion signal\r\n */\r\npublic static Flux<DataBuffer> write(Publisher<? extends DataBuffer> source, AsynchronousFileChannel channel, long position) {\r\n    Assert.notNull(source, \"'source' must not be null\");\r\n    Assert.notNull(channel, \"'channel' must not be null\");\r\n    Assert.isTrue(position >= 0, \"'position' must be >= 0\");\r\n    Flux<DataBuffer> flux = Flux.from(source);\r\n    return Flux.create(sink -> {\r\n        WriteCompletionHandler handler = new WriteCompletionHandler(sink, channel, position);\r\n        sink.onDispose(handler);\r\n        flux.subscribe(handler);\r\n    });\r\n}",
    "comment": "\n\t * Write the given stream of {@link DataBuffer DataBuffers} to the given\n\t * {@code AsynchronousFileChannel}. Does <strong>not</strong> close the channel\n\t * when the flux is terminated, and does <strong>not</strong>\n\t * {@linkplain #release(DataBuffer) release} the data buffers in the source.\n\t * If releasing is required, then subscribe to the returned {@code Flux} with a\n\t * {@link #releaseConsumer()}.\n\t * <p>Note that the writing process does not start until the returned\n\t * {@code Flux} is subscribed to.\n\t * @param source the stream of data buffers to be written\n\t * @param channel the channel to write to\n\t * @param position the file position where writing is to begin; must be non-negative\n\t * @return a flux containing the same buffers as in {@code source}, that\n\t * starts the writing process when subscribed to, and that publishes any\n\t * writing errors and the completion signal\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#write(Publisher<DataBuffer>,Path,OpenOption)",
    "entityType": "method",
    "code": "/**\r\n * Write the given stream of {@link DataBuffer DataBuffers} to the given\r\n * file {@link Path}. The optional {@code options} parameter specifies\r\n * how the file is created or opened (defaults to\r\n * {@link StandardOpenOption#CREATE CREATE},\r\n * {@link StandardOpenOption#TRUNCATE_EXISTING TRUNCATE_EXISTING}, and\r\n * {@link StandardOpenOption#WRITE WRITE}).\r\n * @param source the stream of data buffers to be written\r\n * @param destination the path to the file\r\n * @param options the options specifying how the file is opened\r\n * @return a {@link Mono} that indicates completion or error\r\n * @since 5.2\r\n */\r\npublic static Mono<Void> write(Publisher<DataBuffer> source, Path destination, OpenOption... options) {\r\n    Assert.notNull(source, \"Source must not be null\");\r\n    Assert.notNull(destination, \"Destination must not be null\");\r\n    Set<OpenOption> optionSet = checkWriteOptions(options);\r\n    return Mono.create(sink -> {\r\n        try {\r\n            AsynchronousFileChannel channel = AsynchronousFileChannel.open(destination, optionSet, null);\r\n            sink.onDispose(() -> closeChannel(channel));\r\n            write(source, channel).subscribe(DataBufferUtils::release, sink::error, sink::success, Context.of(sink.contextView()));\r\n        } catch (IOException ex) {\r\n            sink.error(ex);\r\n        }\r\n    });\r\n}",
    "comment": "\n\t * Write the given stream of {@link DataBuffer DataBuffers} to the given\n\t * file {@link Path}. The optional {@code options} parameter specifies\n\t * how the file is created or opened (defaults to\n\t * {@link StandardOpenOption#CREATE CREATE},\n\t * {@link StandardOpenOption#TRUNCATE_EXISTING TRUNCATE_EXISTING}, and\n\t * {@link StandardOpenOption#WRITE WRITE}).\n\t * @param source the stream of data buffers to be written\n\t * @param destination the path to the file\n\t * @param options the options specifying how the file is opened\n\t * @return a {@link Mono} that indicates completion or error\n\t * @since 5.2\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#checkWriteOptions(OpenOption[])",
    "entityType": "method",
    "code": "private static Set<OpenOption> checkWriteOptions(OpenOption[] options) {\r\n    int length = options.length;\r\n    Set<OpenOption> result = CollectionUtils.newHashSet(length > 0 ? length : 2);\r\n    if (length == 0) {\r\n        result.add(StandardOpenOption.CREATE);\r\n        result.add(StandardOpenOption.TRUNCATE_EXISTING);\r\n    } else {\r\n        for (OpenOption opt : options) {\r\n            if (opt == StandardOpenOption.READ) {\r\n                throw new IllegalArgumentException(\"READ not allowed\");\r\n            }\r\n            result.add(opt);\r\n        }\r\n    }\r\n    result.add(StandardOpenOption.WRITE);\r\n    return result;\r\n}",
    "comment": ""
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#closeChannel(Channel)",
    "entityType": "method",
    "code": "static void closeChannel(@Nullable Channel channel) {\r\n    if (channel != null && channel.isOpen()) {\r\n        try {\r\n            channel.close();\r\n        } catch (IOException ignored) ;\r\n    }\r\n}",
    "comment": ""
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#outputStreamPublisher(Consumer<OutputStream>,DataBufferFactory,Executor)",
    "entityType": "method",
    "code": "/**\r\n * Create a new {@code Publisher<DataBuffer>} based on bytes written to a\r\n * {@code OutputStream}.\r\n * <ul>\r\n * <li>The parameter {@code outputStreamConsumer} is invoked once per\r\n * subscription of the returned {@code Publisher}, when the first\r\n * item is\r\n * {@linkplain Subscription#request(long) requested}.</li>\r\n * <li>{@link OutputStream#write(byte[], int, int) OutputStream.write()}\r\n * invocations made by {@code outputStreamConsumer} are buffered until they\r\n * exceed the default chunk size of 1024, or when the stream is\r\n * {@linkplain OutputStream#flush() flushed} and then result in a\r\n * {@linkplain Subscriber#onNext(Object) published} item\r\n * if there is {@linkplain Subscription#request(long) demand}.</li>\r\n * <li>If there is <em>no demand</em>, {@code OutputStream.write()} will block\r\n * until there is.</li>\r\n * <li>If the subscription is {@linkplain Subscription#cancel() cancelled},\r\n * {@code OutputStream.write()} will throw a {@code IOException}.</li>\r\n * <li>The subscription is\r\n * {@linkplain Subscriber#onComplete() completed} when\r\n * {@code outputStreamHandler} completes.</li>\r\n * <li>Any exceptions thrown from {@code outputStreamHandler} will\r\n * be dispatched to the {@linkplain Subscriber#onError(Throwable) Subscriber}.\r\n * </ul>\r\n * @param consumer invoked when the first buffer is requested\r\n * @param executor used to invoke the {@code outputStreamHandler}\r\n * @return a {@code Publisher<DataBuffer>} based on bytes written by\r\n * {@code outputStreamHandler}\r\n * @since 6.1\r\n */\r\npublic static Publisher<DataBuffer> outputStreamPublisher(Consumer<OutputStream> consumer, DataBufferFactory bufferFactory, Executor executor) {\r\n    return new OutputStreamPublisher<>(consumer::accept, new DataBufferMapper(bufferFactory), executor, null);\r\n}",
    "comment": "\n\t * Create a new {@code Publisher<DataBuffer>} based on bytes written to a\n\t * {@code OutputStream}.\n\t * <ul>\n\t * <li>The parameter {@code outputStreamConsumer} is invoked once per\n\t * subscription of the returned {@code Publisher}, when the first\n\t * item is\n\t * {@linkplain Subscription#request(long) requested}.</li>\n\t * <li>{@link OutputStream#write(byte[], int, int) OutputStream.write()}\n\t * invocations made by {@code outputStreamConsumer} are buffered until they\n\t * exceed the default chunk size of 1024, or when the stream is\n\t * {@linkplain OutputStream#flush() flushed} and then result in a\n\t * {@linkplain Subscriber#onNext(Object) published} item\n\t * if there is {@linkplain Subscription#request(long) demand}.</li>\n\t * <li>If there is <em>no demand</em>, {@code OutputStream.write()} will block\n\t * until there is.</li>\n\t * <li>If the subscription is {@linkplain Subscription#cancel() cancelled},\n\t * {@code OutputStream.write()} will throw a {@code IOException}.</li>\n\t * <li>The subscription is\n\t * {@linkplain Subscriber#onComplete() completed} when\n\t * {@code outputStreamHandler} completes.</li>\n\t * <li>Any exceptions thrown from {@code outputStreamHandler} will\n\t * be dispatched to the {@linkplain Subscriber#onError(Throwable) Subscriber}.\n\t * </ul>\n\t * @param consumer invoked when the first buffer is requested\n\t * @param executor used to invoke the {@code outputStreamHandler}\n\t * @return a {@code Publisher<DataBuffer>} based on bytes written by\n\t * {@code outputStreamHandler}\n\t * @since 6.1\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#outputStreamPublisher(Consumer<OutputStream>,DataBufferFactory,Executor,int)",
    "entityType": "method",
    "code": "/**\r\n * Variant of {@link #outputStreamPublisher(Consumer, DataBufferFactory, Executor)}\r\n * providing control over the chunk sizes to be produced by the publisher.\r\n * @since 6.1\r\n */\r\npublic static Publisher<DataBuffer> outputStreamPublisher(Consumer<OutputStream> consumer, DataBufferFactory bufferFactory, Executor executor, int chunkSize) {\r\n    return new OutputStreamPublisher<>(consumer::accept, new DataBufferMapper(bufferFactory), executor, chunkSize);\r\n}",
    "comment": "\n\t * Variant of {@link #outputStreamPublisher(Consumer, DataBufferFactory, Executor)}\n\t * providing control over the chunk sizes to be produced by the publisher.\n\t * @since 6.1\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#subscriberInputStream(Publisher<T>,int)",
    "entityType": "method",
    "code": "/**\r\n * Subscribe to given {@link Publisher} of {@code DataBuffer}s, and return an\r\n * {@link InputStream} to consume the byte content with.\r\n * <p>Byte buffers are stored in a queue. The {@code demand} constructor value\r\n * determines the number of buffers requested initially. When storage falls\r\n * below a {@code (demand - (demand >> 2))} limit, a request is made to refill\r\n * the queue.\r\n * <p>The {@code InputStream} terminates after an onError or onComplete signal,\r\n * and stored buffers are read. If the {@code InputStream} is closed,\r\n * the {@link Flow.Subscription} is cancelled, and stored buffers released.\r\n * @param publisher the source of {@code DataBuffer}s\r\n * @param demand the number of buffers to request initially, and buffer\r\n * internally on an ongoing basis.\r\n * @return an {@link InputStream} backed by the {@link Publisher}\r\n */\r\npublic static <T extends DataBuffer> InputStream subscriberInputStream(Publisher<T> publisher, int demand) {\r\n    Assert.notNull(publisher, \"Publisher must not be null\");\r\n    Assert.isTrue(demand > 0, \"maxBufferCount must be > 0\");\r\n    SubscriberInputStream subscriber = new SubscriberInputStream(demand);\r\n    publisher.subscribe(subscriber);\r\n    return subscriber;\r\n}",
    "comment": "\n\t * Subscribe to given {@link Publisher} of {@code DataBuffer}s, and return an\n\t * {@link InputStream} to consume the byte content with.\n\t * <p>Byte buffers are stored in a queue. The {@code demand} constructor value\n\t * determines the number of buffers requested initially. When storage falls\n\t * below a {@code (demand - (demand >> 2))} limit, a request is made to refill\n\t * the queue.\n\t * <p>The {@code InputStream} terminates after an onError or onComplete signal,\n\t * and stored buffers are read. If the {@code InputStream} is closed,\n\t * the {@link Flow.Subscription} is cancelled, and stored buffers released.\n\t * @param publisher the source of {@code DataBuffer}s\n\t * @param demand the number of buffers to request initially, and buffer\n\t * internally on an ongoing basis.\n\t * @return an {@link InputStream} backed by the {@link Publisher}\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#takeUntilByteCount(Publisher<T>,long)",
    "entityType": "method",
    "code": "//---------------------------------------------------------------------\r\n// Various\r\n//---------------------------------------------------------------------\r\n/**\r\n * Relay buffers from the given {@link Publisher} until the total\r\n * {@linkplain DataBuffer#readableByteCount() byte count} reaches\r\n * the given maximum byte count, or until the publisher is complete.\r\n * @param publisher the publisher to filter\r\n * @param maxByteCount the maximum byte count\r\n * @return a flux whose maximum byte count is {@code maxByteCount}\r\n */\r\n@SuppressWarnings(\"unchecked\")\r\npublic static <T extends DataBuffer> Flux<T> takeUntilByteCount(Publisher<T> publisher, long maxByteCount) {\r\n    Assert.notNull(publisher, \"Publisher must not be null\");\r\n    Assert.isTrue(maxByteCount >= 0, \"'maxByteCount' must be >= 0\");\r\n    return Flux.defer(() -> {\r\n        AtomicLong countDown = new AtomicLong(maxByteCount);\r\n        return Flux.from(publisher).map(buffer -> {\r\n            long remainder = countDown.addAndGet(-buffer.readableByteCount());\r\n            if (remainder < 0) {\r\n                int index = buffer.readableByteCount() + (int) remainder;\r\n                DataBuffer split = buffer.split(index);\r\n                release(buffer);\r\n                return (T) split;\r\n            } else {\r\n                return buffer;\r\n            }\r\n        }).takeUntil(buffer -> countDown.get() <= 0);\r\n    });\r\n    // No doOnDiscard as operators used do not cache (and drop) buffers\r\n}",
    "comment": "\n\t * Relay buffers from the given {@link Publisher} until the total\n\t * {@linkplain DataBuffer#readableByteCount() byte count} reaches\n\t * the given maximum byte count, or until the publisher is complete.\n\t * @param publisher the publisher to filter\n\t * @param maxByteCount the maximum byte count\n\t * @return a flux whose maximum byte count is {@code maxByteCount}\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#skipUntilByteCount(Publisher<T>,long)",
    "entityType": "method",
    "code": "/**\r\n * Skip buffers from the given {@link Publisher} until the total\r\n * {@linkplain DataBuffer#readableByteCount() byte count} reaches\r\n * the given maximum byte count, or until the publisher is complete.\r\n * @param publisher the publisher to filter\r\n * @param maxByteCount the maximum byte count\r\n * @return a flux with the remaining part of the given publisher\r\n */\r\npublic static <T extends DataBuffer> Flux<T> skipUntilByteCount(Publisher<T> publisher, long maxByteCount) {\r\n    Assert.notNull(publisher, \"Publisher must not be null\");\r\n    Assert.isTrue(maxByteCount >= 0, \"'maxByteCount' must be >= 0\");\r\n    return Flux.defer(() -> {\r\n        AtomicLong countDown = new AtomicLong(maxByteCount);\r\n        return Flux.from(publisher).skipUntil(buffer -> {\r\n            long remainder = countDown.addAndGet(-buffer.readableByteCount());\r\n            return remainder < 0;\r\n        }).map(buffer -> {\r\n            long remainder = countDown.get();\r\n            if (remainder < 0) {\r\n                countDown.set(0);\r\n                int start = buffer.readableByteCount() + (int) remainder;\r\n                DataBuffer split = buffer.split(start);\r\n                release(split);\r\n                return buffer;\r\n            } else {\r\n                return buffer;\r\n            }\r\n        });\r\n    }).doOnDiscard(DataBuffer.class, DataBufferUtils::release);\r\n}",
    "comment": "\n\t * Skip buffers from the given {@link Publisher} until the total\n\t * {@linkplain DataBuffer#readableByteCount() byte count} reaches\n\t * the given maximum byte count, or until the publisher is complete.\n\t * @param publisher the publisher to filter\n\t * @param maxByteCount the maximum byte count\n\t * @return a flux with the remaining part of the given publisher\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#retain(T)",
    "entityType": "method",
    "code": "/**\r\n * Retain the given data buffer, if it is a {@link PooledDataBuffer}.\r\n * @param dataBuffer the data buffer to retain\r\n * @return the retained buffer\r\n */\r\n@SuppressWarnings(\"unchecked\")\r\npublic static <T extends DataBuffer> T retain(T dataBuffer) {\r\n    if (dataBuffer instanceof PooledDataBuffer pooledDataBuffer) {\r\n        return (T) pooledDataBuffer.retain();\r\n    } else {\r\n        return dataBuffer;\r\n    }\r\n}",
    "comment": "\n\t * Retain the given data buffer, if it is a {@link PooledDataBuffer}.\n\t * @param dataBuffer the data buffer to retain\n\t * @return the retained buffer\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#touch(T,Object)",
    "entityType": "method",
    "code": "/**\r\n * Associate the given hint with the data buffer if it is a pooled buffer\r\n * and supports leak tracking.\r\n * @param dataBuffer the data buffer to attach the hint to\r\n * @param hint the hint to attach\r\n * @return the input buffer\r\n * @since 5.3.2\r\n */\r\n@SuppressWarnings(\"unchecked\")\r\npublic static <T extends DataBuffer> T touch(T dataBuffer, Object hint) {\r\n    if (dataBuffer instanceof TouchableDataBuffer touchableDataBuffer) {\r\n        return (T) touchableDataBuffer.touch(hint);\r\n    } else {\r\n        return dataBuffer;\r\n    }\r\n}",
    "comment": "\n\t * Associate the given hint with the data buffer if it is a pooled buffer\n\t * and supports leak tracking.\n\t * @param dataBuffer the data buffer to attach the hint to\n\t * @param hint the hint to attach\n\t * @return the input buffer\n\t * @since 5.3.2\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#release(DataBuffer)",
    "entityType": "method",
    "code": "/**\r\n * Release the given data buffer. If it is a {@link PooledDataBuffer} and\r\n * has been {@linkplain PooledDataBuffer#isAllocated() allocated}, this\r\n * method will call {@link PooledDataBuffer#release()}. If it is a\r\n * {@link CloseableDataBuffer}, this method will call\r\n * {@link CloseableDataBuffer#close()}.\r\n * @param dataBuffer the data buffer to release\r\n * @return {@code true} if the buffer was released; {@code false} otherwise.\r\n */\r\npublic static boolean release(@Nullable DataBuffer dataBuffer) {\r\n    if (dataBuffer instanceof PooledDataBuffer pooledDataBuffer) {\r\n        if (pooledDataBuffer.isAllocated()) {\r\n            try {\r\n                return pooledDataBuffer.release();\r\n            } catch (IllegalStateException ex) {\r\n                if (logger.isDebugEnabled()) {\r\n                    logger.debug(\"Failed to release PooledDataBuffer: \" + dataBuffer, ex);\r\n                }\r\n                return false;\r\n            }\r\n        }\r\n    } else if (dataBuffer instanceof CloseableDataBuffer closeableDataBuffer) {\r\n        try {\r\n            closeableDataBuffer.close();\r\n            return true;\r\n        } catch (IllegalStateException ex) {\r\n            if (logger.isDebugEnabled()) {\r\n                logger.debug(\"Failed to release CloseableDataBuffer \" + dataBuffer, ex);\r\n            }\r\n            return false;\r\n        }\r\n    }\r\n    return false;\r\n}",
    "comment": "\n\t * Release the given data buffer. If it is a {@link PooledDataBuffer} and\n\t * has been {@linkplain PooledDataBuffer#isAllocated() allocated}, this\n\t * method will call {@link PooledDataBuffer#release()}. If it is a\n\t * {@link CloseableDataBuffer}, this method will call\n\t * {@link CloseableDataBuffer#close()}.\n\t * @param dataBuffer the data buffer to release\n\t * @return {@code true} if the buffer was released; {@code false} otherwise.\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#releaseConsumer()",
    "entityType": "method",
    "code": "/**\r\n * Return a consumer that calls {@link #release(DataBuffer)} on all\r\n * passed data buffers.\r\n */\r\npublic static Consumer<DataBuffer> releaseConsumer() {\r\n    return RELEASE_CONSUMER;\r\n}",
    "comment": "\n\t * Return a consumer that calls {@link #release(DataBuffer)} on all\n\t * passed data buffers.\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#join(Publisher<? extends DataBuffer>)",
    "entityType": "method",
    "code": "/**\r\n * Return a new {@code DataBuffer} composed of joining together the given\r\n * {@code dataBuffers} elements. Depending on the {@link DataBuffer} type,\r\n * the returned buffer may be a single buffer containing all data of the\r\n * provided buffers, or it may be a zero-copy, composite with references to\r\n * the given buffers.\r\n * <p>If {@code dataBuffers} produces an error or if there is a cancel\r\n * signal, then all accumulated buffers will be\r\n * {@linkplain #release(DataBuffer) released}.\r\n * <p>Note that the given data buffers do <strong>not</strong> have to be\r\n * released. They will be released as part of the returned composite.\r\n * @param dataBuffers the data buffers that are to be composed\r\n * @return a buffer that is composed of the {@code dataBuffers} argument\r\n * @since 5.0.3\r\n */\r\npublic static Mono<DataBuffer> join(Publisher<? extends DataBuffer> dataBuffers) {\r\n    return join(dataBuffers, -1);\r\n}",
    "comment": "\n\t * Return a new {@code DataBuffer} composed of joining together the given\n\t * {@code dataBuffers} elements. Depending on the {@link DataBuffer} type,\n\t * the returned buffer may be a single buffer containing all data of the\n\t * provided buffers, or it may be a zero-copy, composite with references to\n\t * the given buffers.\n\t * <p>If {@code dataBuffers} produces an error or if there is a cancel\n\t * signal, then all accumulated buffers will be\n\t * {@linkplain #release(DataBuffer) released}.\n\t * <p>Note that the given data buffers do <strong>not</strong> have to be\n\t * released. They will be released as part of the returned composite.\n\t * @param dataBuffers the data buffers that are to be composed\n\t * @return a buffer that is composed of the {@code dataBuffers} argument\n\t * @since 5.0.3\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#join(Publisher<? extends DataBuffer>,int)",
    "entityType": "method",
    "code": "/**\r\n * Variant of {@link #join(Publisher)} that behaves the same way up until\r\n * the specified max number of bytes to buffer. Once the limit is exceeded,\r\n * {@link DataBufferLimitException} is raised.\r\n * @param buffers the data buffers that are to be composed\r\n * @param maxByteCount the max number of bytes to buffer, or -1 for unlimited\r\n * @return a buffer with the aggregated content, possibly an empty Mono if\r\n * the max number of bytes to buffer is exceeded.\r\n * @throws DataBufferLimitException if maxByteCount is exceeded\r\n * @since 5.1.11\r\n */\r\n@SuppressWarnings({ \"rawtypes\", \"unchecked\" })\r\npublic static Mono<DataBuffer> join(Publisher<? extends DataBuffer> buffers, int maxByteCount) {\r\n    Assert.notNull(buffers, \"'buffers' must not be null\");\r\n    if (buffers instanceof Mono mono) {\r\n        return mono;\r\n    }\r\n    return Flux.from(buffers).collect(() -> new LimitedDataBufferList(maxByteCount), LimitedDataBufferList::add).filter(list -> !list.isEmpty()).map(list -> list.get(0).factory().join(list)).doOnDiscard(DataBuffer.class, DataBufferUtils::release);\r\n}",
    "comment": "\n\t * Variant of {@link #join(Publisher)} that behaves the same way up until\n\t * the specified max number of bytes to buffer. Once the limit is exceeded,\n\t * {@link DataBufferLimitException} is raised.\n\t * @param buffers the data buffers that are to be composed\n\t * @param maxByteCount the max number of bytes to buffer, or -1 for unlimited\n\t * @return a buffer with the aggregated content, possibly an empty Mono if\n\t * the max number of bytes to buffer is exceeded.\n\t * @throws DataBufferLimitException if maxByteCount is exceeded\n\t * @since 5.1.11\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#matcher(byte[])",
    "entityType": "method",
    "code": "/**\r\n * Return a {@link Matcher} for the given delimiter.\r\n * The matcher can be used to find the delimiters in a stream of data buffers.\r\n * @param delimiter the delimiter bytes to find\r\n * @return the matcher\r\n * @since 5.2\r\n */\r\npublic static Matcher matcher(byte[] delimiter) {\r\n    return createMatcher(delimiter);\r\n}",
    "comment": "\n\t * Return a {@link Matcher} for the given delimiter.\n\t * The matcher can be used to find the delimiters in a stream of data buffers.\n\t * @param delimiter the delimiter bytes to find\n\t * @return the matcher\n\t * @since 5.2\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#matcher(byte[])",
    "entityType": "method",
    "code": "/**\r\n * Return a {@link Matcher} for the given delimiters.\r\n * The matcher can be used to find the delimiters in a stream of data buffers.\r\n * @param delimiters the delimiters bytes to find\r\n * @return the matcher\r\n * @since 5.2\r\n */\r\npublic static Matcher matcher(byte[]... delimiters) {\r\n    Assert.isTrue(delimiters.length > 0, \"Delimiters must not be empty\");\r\n    return (delimiters.length == 1 ? createMatcher(delimiters[0]) : new CompositeMatcher(delimiters));\r\n}",
    "comment": "\n\t * Return a {@link Matcher} for the given delimiters.\n\t * The matcher can be used to find the delimiters in a stream of data buffers.\n\t * @param delimiters the delimiters bytes to find\n\t * @return the matcher\n\t * @since 5.2\n\t "
  },
  {
    "entityId": "org.springframework.core.io.buffer.DataBufferUtils#createMatcher(byte[])",
    "entityType": "method",
    "code": "private static NestedMatcher createMatcher(byte[] delimiter) {\r\n    // extract length due to Eclipse IDE compiler error in switch expression\r\n    int length = delimiter.length;\r\n    Assert.isTrue(length > 0, \"Delimiter must not be empty\");\r\n    return switch(length) {\r\n        case 1 ->\r\n            (delimiter[0] == 10 ? SingleByteMatcher.NEWLINE_MATCHER : new SingleByteMatcher(delimiter));\r\n        case 2 ->\r\n            new TwoByteMatcher(delimiter);\r\n        default ->\r\n            new KnuthMorrisPrattMatcher(delimiter);\r\n    };\r\n}",
    "comment": ""
  },
  {
    "entityId": "org.springframework.core.io.buffer.Matcher",
    "entityType": "class",
    "code": "/**\r\n * Find the first matching delimiter and return the index of the last\r\n * byte of the delimiter, or {@code -1} if not found.\r\n */\r\nint match(DataBuffer dataBuffer);\n/**\r\n * Return the delimiter from the last invocation of {@link #match(DataBuffer)}.\r\n */\r\nbyte[] delimiter();\n/**\r\n * Reset the state of this matcher.\r\n */\r\nvoid reset();",
    "comment": "\n\t * Contract to find delimiter(s) against one or more data buffers that can\n\t * be passed one at a time to the {@link #match(DataBuffer)} method.\n\t *\n\t * @since 5.2\n\t * @see #match(DataBuffer)\n\t "
  }
]